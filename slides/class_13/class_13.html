<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Análisis de Datos Categóricos (SOC3070)</title>
    <meta charset="utf-8" />
    <meta name="author" content="  Mauricio Bucca  Profesor Asistente, Sociología UC" />
    <script src="libs/header-attrs-2.24/header-attrs.js"></script>
    <link rel="stylesheet" href="gentle-r.css" type="text/css" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Análisis de Datos Categóricos (SOC3070)
]
.subtitle[
## Clase #13: Regresión Logística Multinomial
]
.author[
### <br> Mauricio Bucca<br> Profesor Asistente, Sociología UC
]
.date[
### 12 November, 2023
]

---

class: inverse, center, middle



# Regresión Logística Multinomial


---
## Estructura de un modelo de regresión logística multinomial 

`$$\newcommand{\vect}[1]{\boldsymbol{#1}}$$`
Un modelo de regresión logística multinomial generaliza la regresión logística (binomial) a situaciones en que la variable dependiente es una .bold[variable discreta con dos o más valores no ordenados] (ejemplo: voto entre tres candidatos, elección de barrio, etc).

&lt;br&gt;
--

.bold[Configuración]

- Tenemos `\(n\)` observaciones (individuos) independientes: `\(i = 1, \dots, n\)`

--

- Para cada observación observamos datos `\(y_{i}, \dots , y_{n}\)` que actúan como variable dependiente, donde `\(y_{i} \in \{j:1,2, \cdots, J\}\)`
  
  - Las `\(J\)` categorías de `\(y_{i}\)` no siguen necesariamente un orden.

--

- Asumimos que estos datos son realizaciones de `\(n\)` variables aleatorias que siguen una distribución Multinomial con probabilidades desconocidas: `\(Y_{i} \sim \text{Multinomial}(\vect{p_{i}}: p_{1}, \dots, p_{J})\)`

--

- Dichas probabilidades, `\(\vect{p_{i}}\)`, varían de individuo en individuo en función de ciertas covariables.


---
## Distribución Multinomial

&lt;br&gt;
.bold[Distribución Multinomial:]

- Dado un experimento con resultados posibles `\(\{1,2, \dots, J\}\)`, con respectiva probabilidad de "éxito" `\(\{p_1,p_2, \dots, p_J\}\)` 

--

- Si repetimos el experimento `\(n\)` veces: ¿Cuál es la probabilidad de obtener la siguiente cantidad de éxitos en cada categoría: `\(\{n_1,n_2, \dots, n_J\}\)`, donde `\(n_1 + n_2 + \dots + n_J =n\)`?
  
&lt;br&gt;
--

.bold[Ejemplo]: Al tirar un dado justo 12 veces, ¿cuál es la probabilidad de obtener cada lado 2 veces?


```r
dmultinom(x=c(2,2,2,2,2,2), size=12 ,p=c(1/6,1/6,1/6,1/6,1/6,1/6))
```

```
## [1] 0.003438286
```

---
## Distribución Multinomial (n=1)


.bold[Distribución Multinoulli o Categórica:]

Si la cantidad de intentos es igual a 1 (n=1), la probabilidad de éxito en una de las categorías (y fracaso en todas las otras) viene definida por la siguiente función de probabilidad:
 
--

`$$\quad \mathbb{P}(Y = j ) = p_{1}^{1[y=1]}p_{2}^{1[y=2]} \cdots p_{J}^{1[y=J]}    \quad \text{ donde } \quad y_{j} \in \{0,1\} \quad \text{y} \quad \sum^{J}_{j=1}1[y=j]=1$$`

--

.bold[Ejemplo]: Al tirar un dado justo 1 vez, ¿cuál es la probabilidad de obtener el número 4?


```r
dmultinom(x=c(0,0,0,1,0,0), size=1 ,p=c(1/6,1/6,1/6,1/6,1/6,1/6))
```

```
## [1] 0.1666667
```

--

- En una regresión logística multinomial cada observación en la variable dependiente ( `\(y_{i}\)` ) viene de una distribución Multinoulli.

--

- Observamos los resultados ( `\(y_{i}=j\)` ) y queremos estimar las probabilidades que los generan, ( `\(p_{ij}\)` ).

--
 
- Específicamente, queremos estimar ( `\(p_{ij}\)` ) como un función de covariables , usando número de parámetros `\(k\)`, tal que `\(k&lt;n\)`.



---
## Regresión logística binomial


Una regresión logística binomial `\(y_{i} \in {0,1}\)`

.content-box-yellow[
`$$\ln \frac{\mathbb{P}(y_{i}=1)}{\mathbb{P}(y_{i}=0)} =   \ln \frac{p_{i}}{1 - p_{i}} = \beta_{0} + \beta_{1}x_{1i} + \dots + \beta_{k}x_{ki}$$`] 


&lt;br&gt;
--

Equivalentemente, podemos re-escribir el modelo como

&lt;br&gt;

`$$\ln \frac{\mathbb{P}(y_{i}=1)}{\mathbb{P}(y_{i}=0)} =   \ln \frac{p_{1i}}{p_{0i}} =  \beta_{0} + \beta_{1}x_{1i} + \dots + \beta_{k}x_{ki}$$`
&lt;br&gt;
--

Dado que `\(p_{0} + p_{1} = 1\)`, sólo necesitamos estimar una equación.


---
## Regresión logística multinomial, 3 categorías 


Si la variable dependiente toma tres valores, `\(y \in \{1,2,3\}\)`, y las probabilidades de obtener estos resultados son `\(p_{1},p_{2},p_{3}\)`, entonces podemos estimar estas tres probabilidades con dos modelos de regresión logística:

&lt;br&gt;
--

Usando `\(p_{3}\)` como categoría de referencia:


`$$(1) \quad \ln \frac{\mathbb{P}(y_{i}=1)}{\mathbb{P}(y_{i}=3)} =   \ln \frac{p_{1i}}{p_{3i}} =  \beta_{10} + \beta_{11}x_{1i} + \dots + \beta_{1k}x_{ki}$$`
--
&lt;br&gt; y

`$$(2) \quad \ln \frac{\mathbb{P}(y_{i}=2)}{\mathbb{P}(y_{i}=3)} =   \ln \frac{p_{2i}}{p_{3i}} =  \beta_{20} + \beta_{21}x_{1i} + \dots + \beta_{2k}x_{ki}$$`
&lt;br&gt;
--

Describimos `\(\{(p_{1},p_{2},p_{3})_{i}, \quad  \dots \quad ,(p_{1},p_{2},p_{3})_{n}\}\)` con `\(2(k + 1)\)` parámetros.

---
## Regresión logística multinomial, J-categorías 

Generalizando, si la variable dependiente toma, `\(J\)` valores -- `\(y \in \{1,2,\dots,J\}\)` -- , y las probabilidades de obtener estos resultados son `\(p_{1},p_{2},\dots,p_{J}\)`, entonces podemos estimar estas `\(J\)` probabilidades con  `\(J-1\)` modelos de regresión logística:

--

Usando `\(p_{J}\)` como categoría de referencia:

`$$(1) \quad \ln \frac{\mathbb{P}(y_{i}=1)}{\mathbb{P}(y_{i}=J)} =   \ln \frac{p_{1i}}{p_{Ji}} =  \beta_{10} + \beta_{11}x_{1i} + \dots + \beta_{1k}x_{ki}$$`
--

`$$(2) \quad \ln \frac{\mathbb{P}(y_{i}=2)}{\mathbb{P}(y_{i}=J)} =   \ln \frac{p_{2i}}{p_{Ji}} =  \beta_{20} + \beta_{21}x_{1i} + \dots + \beta_{2k}x_{ki}$$`
--

`$$\vdots$$`
--

`$$(J-1) \quad \ln \frac{\mathbb{P}(y_{i}=J-1)}{\mathbb{P}(y_{i}=J)} =   \ln \frac{p_{(J-1)i}}{p_{Ji}} =  \beta_{(J-1)0} + \beta_{(J-1)1}x_{1i} + \dots + \beta_{(J-1)k}x_{ki}$$`

---
## Regresión logística multinomial, J-categorías 

Una versión más compacta de lo expresado anteriormente lleva a la formulación estándar de un modelo de regresión multinomial:

&lt;br&gt;
--

.content-box-yellow[
`$$\underbrace{\ln \frac{\mathbb{P}(y_{i}=j)}{\mathbb{P}(y_{i}=J)}}_{\text{log odds = log relative probability}}=   \ln \frac{p_{ji}}{p_{Ji}} = \overbrace{ \beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}^{\text{predictor lineal }j}$$`
]

&lt;br&gt;
--

Describimos `\(\{(p_{1},\dots,p_{J})_{i}, \quad  \dots \quad ,(p_{1},\dots,p_{J})_{n}\}\)` con `\((J-1)(k+1)\)` parámetros.

---
## Regresión logística multinomial, J-categorías 

De la formulación anterior es posible derivar el contraste en todos los restantes pares de categorías.
--

 Consideremos las categorías `\(a\)` y `\(b\)`:

--

`$$\ln \frac{p_{ai}}{p_{bi}} =  \ln \frac{p_{ai}/p_{Ji}}{p_{bi}/p_{Ji}} = \ln \frac{p_{ai}}{p_{Ji}} - \ln \frac{p_{bi}}{p_{Ji}}$$`
--
Por tanto,


`$$\ln \frac{p_{ai}}{p_{bi}} =  (\beta_{a0} + \beta_{a1}x_{1i} + \dots + \beta_{ak}x_{ki}) - (\beta_{b0} + \beta_{b1}x_{1i} + \dots + \beta_{bk}x_{ki})$$`
--
En resumen:

.content-box-yellow[
`$$\ln \frac{p_{ai}}{p_{bi}} =  (\beta_{a0} -\beta_{b0}) + (\beta_{a1} - \beta_{b1}) x_{1i} + \dots + (\beta_{ak} - \beta_{bk}) x_{ki}$$`
]

donde cada `\((\beta_{ak} -\beta_{bk})\)` es un coeficiente en si mismo.
---
## Regresión logística multinomial expresada como probabilidades

Dado

`$$\ln \frac{p_{ji}}{p_{Ji}} =  \beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}$$`
&lt;br&gt;
--

-  Exponenciando en ambos lados obtenemos la probabilidad "relativa" entre las categorías `\(j\)` y `\(J\)`:

`$$\frac{p_{ji}}{p_{Ji}} =  e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}$$`
&lt;br&gt;
--

- Luego, la probabilidad de obtener la categoría `\(j\)` puede ser expresada como sigue:

`$$p_{ji}  =  p_{Ji} \cdot e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}$$`

---
## Regresión logística multinomial expresada como probabilidades

La expresión `\(p_{ji}  =  p_{Ji} \cdot e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}\)` significa que:


&lt;br&gt;
--


`$$p_{1i}  =  p_{Ji} \cdot e^{\beta_{10} + \beta_{11}x_{1i} + \dots + \beta_{1k}x_{ki}}$$`
&lt;br&gt;
--


`$$p_{2i}  =  p_{Ji} \cdot e^{\beta_{20} + \beta_{21}x_{1i} + \dots + \beta_{2k}x_{ki}}$$`
&lt;br&gt;
--

`$$\vdots$$`
&lt;br&gt;
--
`$$p_{(J-1)i}  =  p_{Ji} \cdot e^{\beta_{(J-1)0} + \beta_{(J-1)1}x_{1i} + \dots + \beta_{(J-1)k}x_{ki}}$$`

&lt;br&gt;
--


Luego, falta sólo determinar `\(p_{Ji}\)`.

---
## Regresión logística multinomial expresada como probabilidades


Para determinar `\(p_{Ji}\)` usamos los siguientes hechos:

--

.pull-left[
`$$\text{(1)} \quad p_{ji}  =  p_{Ji} \cdot e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}$$`
]

.pull-right[
`$$\text{(2)} \quad   p_{1i} + p_{2i} + \dots + p_{Ji} = 1$$`
]

&lt;br&gt;
--

Combinando (1) y (2) obtenemos que:

`$$\sum^{J-1}_{j=1} p_{Ji} \cdot e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}} + p_{Ji} = 1, \quad \text{luego ... }$$`
--


`$$p_{Ji} \bigg(\sum^{J-1}_{j=1}  e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}} + 1 \bigg) = 1, \quad \text{por tanto ... }$$`

--

.content-box-yellow[
`$$p_{Ji} =\frac{1}{1 + \sum^{J-1}_{j=1}  e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}}$$`
]

---
## Regresión logística multinomial expresada como probabilidades

Ahora sabemos que:

--

- `\(p_{Ji} =\frac{1}{1 + \sum^{J-1}_{j=1}  e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}}\)` 

- `\(p_{ji}  =  p_{Ji} \cdot e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}\)`

&lt;br&gt;
--
Combinando ambos resultados obtenemos:


.content-box-yellow[
`$$p_{ji} =\frac{e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}}{1 + \sum^{J-1}_{j=1}  e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}}$$`
]

---
## Regresión logística multinomial en la práctica

Para ejemplificar el uso de regresión logística multinomial trabajaremos con los datos de intención de voto en el plebiscito de 1988. 


```
## # A tibble: 2,700 × 8
##    region population sex     age education income statusquo vote 
##    &lt;fct&gt;       &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;fct&gt;
##  1 C          175000 F        64 P             NA     -1.80 U    
##  2 M           25000 M        27 S           7500     -1.74 &lt;NA&gt; 
##  3 SA         250000 F        21 PS         35000     -1.73 N    
##  4 SA         250000 F        42 S          35000     -1.48 &lt;NA&gt; 
##  5 SA         250000 M        27 S           7500     -1.34 N    
##  6 C          250000 F        22 S           7500     -1.33 N    
##  7 M           15000 M        34 P          15000     -1.33 N    
##  8 SA         250000 M        66 S          35000     -1.31 &lt;NA&gt; 
##  9 SA         250000 F        25 S          15000     -1.31 A    
## 10 S          250000 F        39 S          15000     -1.31 N    
## # ℹ 2,690 more rows
```

&lt;br&gt;
`vote`: (A) Abstención; (N) NO; (U) Indecisa; (Y) SI

`statusquo`: apoyo al status-quo (+)

---
## Regresión logística multinomial en la práctica


```r
mlogit_vote_sq &lt;- multinom(vote ~ statusquo, trace=F, data=plebs_1988); 
summary(mlogit_vote_sq)
```

```
## Call:
## multinom(formula = vote ~ statusquo, data = plebs_1988, trace = F)
## 
## Coefficients:
##   (Intercept) statusquo
## N   0.4944577 -1.732813
## U   1.1683095  0.328358
## Y   0.7272056  1.892946
## 
## Std. Errors:
##   (Intercept) statusquo
## N  0.11122679 0.1268217
## U  0.08618457 0.1034620
## Y  0.10093053 0.1180262
## 
## Residual Deviance: 4383.674 
## AIC: 4395.674
```

---
## Regresión logística multinomial en la práctica


.pull-left[
![](class_13_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;
]

--

.pull-right[
![](class_13_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;
]

---
class: inverse, center, middle

## Estimación

---
## Estimación


&lt;br&gt;
--

- Parámetros son estimados via MLE

--

- Alternativamente, minimizando función `\(softmax\)`  (ej, paquete `nnet` en `R`)

--

- Las `\(J-1\)` equaciones del modelo de regresión logística son estimadas simultáneamente, imponiendo la restricción: `\(\sum_{j}p_{i} = 1\)`  ("constrained optimization")

--

- Es posible estimar `\(J-1\)` regresiones logísticas separadamente pero no garantiza que `\(\sum_{j}p_{i} = 1\)`.


---
class: inverse, center, middle

## Interpretación

---
class:center, middle

## Efectos marginales sobre el logit 


---
## Un ejemplo empírico

.pull-left[
Continuando con los datos del plebiscito de 1988, ajustaremos el siguiente modelo:

`$$\ln \frac{p_{ij}}{p_{iJ}} = \beta_{j0} + \beta_{j1}\text{statusquo}_{i} + \beta_{j2}\text{male}_{i}$$`

donde:

- `\(p_{iJ} =\mathbb{P}(\text{vote}_{i}=\text{A})\)`

- `\(p_{ij} =\mathbb{P}(\text{vote}_{i}=j), \quad j \in \{\text{N},\text{U},\text{Y}\}\)`

- `\(\text{logit}(p_{ij})\)` es el .bold[log odds] de votar N/U/Y vs A.

- `\(p_{ij}\)`'s  son una función de apoyo al status-quo (statusquo) y género (sex)

]

--
.pull-right[

```r
mlogit_vote_sq_sex &lt;- multinom(vote ~ statusquo + sex, trace=F, data=plebs_1988); 
summary(mlogit_vote_sq_sex)
```

```
## Call:
## multinom(formula = vote ~ statusquo + sex, data = plebs_1988, 
##     trace = F)
## 
## Coefficients:
##   (Intercept)  statusquo       sexM
## N   0.1099473 -1.7644993  0.6981650
## U   1.2905014  0.3357059 -0.2920198
## Y   0.7772821  1.8948940 -0.1141098
## 
## Std. Errors:
##   (Intercept) statusquo      sexM
## N   0.1435548 0.1284951 0.1727614
## U   0.1143529 0.1035609 0.1716492
## Y   0.1289686 0.1181259 0.1794425
## 
## Residual Deviance: 4322.571 
## AIC: 4340.571
```
]

---
## Efectos marginales sobre el logit

Un modelo de regresión logística multinomial consiste de `\(J-1\)` ecuaciones:

`$$\text{logit}(p_{ij}) = \ln \frac{p_{ij}}{p_{iJ}} = \beta_{j0} + \beta_{j1} x_{i1} + \dots + \beta_{jk} x_{ik}$$`
--

- El intercepto `\(\beta_{j0}\)` corresponde al log del ratio entre la probabilidad de obtener `\(j\)` en vez de `\(J\)` -- `\(\text{logit}(p_{j})\)` --, cuando `\(x_{1} = \dots = x_{k} = 0\)`

--

- El efecto marginal de `\(x_{k}\)` sobre el `\(\text{logit}(p_{j})\)` por:


.pull-left[
.content-box-blue[
`$$\frac{\partial\text{logit}(p_{ij})}{\partial x_{k}} = \beta_{jk}$$`
]
]
.pull-right[
.content-box-yellow[
"Un cambio infinitesimal en `\(x_{k}\)`  ( `\(\partial x_{k}\)` ) se traduce en un cambio en `\(\partial x_{k} \beta_{jk}\)` unidades en el `\(\text{logit}(p_{j})\)`"
] 
]

--

.bold[Importante:] los coeficientes y sus transformaciones entregan información sobre las probabilidades .bold[relativas] de los diferentes `\(j\)`'s (con respecto a categoría de referencia).

---
## Efectos marginales sobre el logit 

En nuestro ejemplo: `\(\ln \frac{p_{ij}}{p_{iJ}} = \beta_{j0} + \beta_{j1}\text{statusquo}_{i} + \beta_{j2}\text{male}_{i}\)`

&lt;br&gt;

.pull-left[

```
##   (Intercept)  statusquo       sexM
## N   0.1099473 -1.7644993  0.6981650
## U   1.2905014  0.3357059 -0.2920198
## Y   0.7772821  1.8948940 -0.1141098
```
]
.pull-right[
![](class_13_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;
]


---
## Efectos marginales sobre el logit 

.pull-left[

```
##   (Intercept)  statusquo       sexM
## N   0.1099473 -1.7644993  0.6981650
## U   1.2905014  0.3357059 -0.2920198
## Y   0.7772821  1.8948940 -0.1141098
```
]

.pull-right[
Si `male=1` y `statusquo=0`, entonces `logit(p_N)` y `logit(p_Y)` son=

```r
c(N=0.11 -1.76*0 + 0.7*1,
  Y=0.78  + 1.9*0 + -0.11*1)
```

```
##    N    Y 
## 0.81 0.67
```

Si `male=1` y `statusquo=1`, entonces `logit(p_N)` y `logit(p_Y)` son=

```r
c(N=0.11 -1.76*1 + 0.7*1,
  Y=0.78  + 1.9*1 + -0.11*1)
```

```
##     N     Y 
## -0.95  2.57
```
]


---
## Efectos marginales sobre el logit 

.pull-left[

```
##   (Intercept)  statusquo       sexM
## N   0.1099473 -1.7644993  0.6981650
## U   1.2905014  0.3357059 -0.2920198
## Y   0.7772821  1.8948940 -0.1141098
```

&lt;br&gt;
Por tanto, `\(\beta_{N1}\)` y `\(\beta_{Y1}\)` son=



```r
c(
betaN1 = (0.11 -1.76*1 + 0.7*1)-(0.11 -1.76*0 + 0.7*1),
betaY1 = (0.78 + 1.9*1 -0.11*1)-(0.78 + 1.9*0 -0.11*1)
)
```

```
## betaN1 betaY1 
##  -1.76   1.90
```

]

.pull-right[
Si `male=1` y `statusquo=0`, entonces `logit(p_N)` y `logit(p_Y)` son=

```r
c(N=0.11 -1.76*0 + 0.7*1,
  Y=0.78  + 1.9*0 + -0.11*1)
```

```
##    N    Y 
## 0.81 0.67
```

Si `male=1` y `statusquo=1`, entonces `logit(p_N)` y `logit(p_Y)` son=

```r
c(N=0.11 -1.76*1 + 0.7*1,
  Y=0.78  + 1.9*1 + -0.11*1)
```

```
##     N     Y 
## -0.95  2.57
```
]

---
class:center, middle

## Efectos multiplicativos sobre las odds 


---
## Efectos multiplicativos sobre las odds 

Dado el siguiente modelo de regresión logística multinomial: 


`$$\text{logit}(p_{ij}) = \ln \frac{p_{ij}}{p_{iJ}} = \beta_{j0} + \beta_{j1} x_{i1} + \dots + \beta_{jk} x_{ik}$$`

&lt;br&gt;
--

exponenciando a ambos lados obtenemos 

`$$\frac{p_{ij}}{p_{iJ}} = e^{\beta_{j0} + \beta_{j1} x_{i1} + \dots + \beta_{jk} x_{ik}}$$`

--

equivalentemente

.content-box-blue[
`$$\frac{p_{ij}}{p_{iJ}} =  e^{\beta_{j0}} \cdot e^{\beta_{j1} x_{i1}}  \dots e^{\beta_{jk} x_{ik}}$$`
]

---
## Efectos multiplicativos sobre las odds: odds ratios

Considera la situación en que `\(i\)` y `\(i^{´}\)` son dos observaciones con `\(x_{k}=c\)` y `\(x_{k}=c+1\)`, respectivamente. El resto de las covariables toman valores idénticos. 
--
 Las odds de observar `\(j\)` en vez de `\(J\)` son:


- `\(p_{ij}/(p_{iJ}) = e^{\beta_{j0}} \cdot e^{\beta_{j1} x_{i1}}  \dots (e^{\beta_{jk}})^{c}\)`

- `\(p_{i^{´}j}/(p_{i^{´}J}) = e^{\beta_{j0}} \cdot e^{\beta_{j1} x_{i^{´}1}}  \dots (e^{\beta_{jk}})^{c+1}\)`


&lt;br&gt;
--

El ratio de las odd de éxito entre `\(i^{´}\)` e `\(i\)` está dado por:

`\begin{align}
\frac{p_{i^{´}j}/p_{i^{´}J}}{p_{ij}/p_{iJ}} &amp;= \frac{e^{\beta_{j0}} \cdot e^{\beta_{j1} x_{i^{´}1}}  \dots (e^{\beta_{jk}})^{c+1}}{e^{\beta_{j0}} \cdot e^{\beta_{j1} x_{i1}}  \dots (e^{\beta_{jk}})^{c}} = e^{\beta_{jk}}
\end{align}`

&lt;br&gt;
En otras palabras, manteniendo otros factores constantes, `\(e^{\beta_{jk}}\)` representa la odds ratio de `\(j\)` vs `\(J\)` entre el caso con `\(x_{k}\)` aumentado en una unidad, y el caso con `\(x_{k}\)` en un nivel basal dado. 

---
## Efectos multiplicativos sobre las odds 


.content-box-yellow[
"Un cambio en `\(\Delta\)` unidades de `\(x_{k}\)` multiplica el ratio entre las probabilidad de obtener `\(j\)` vs `\(J\)` por `\(e^{\Delta \beta_{jk}}\)`"
] 

&lt;br&gt;
.bold[Propiedades]:

--

- `\(e^{\beta_{jk}}\)` está restringido al rango `\([0,\infty+)\)`. Es una constante que "comprime" o amplifica el ratio entre las probabilidades de `\(j\)` vs `\(J\)`

--

- Si `\(\beta_{jk} &lt; 0  \to  (0 &lt; e^{\beta_{jk}} &lt; 1)\)`. Es decir, un aumento en `\(x_{k}\)` está asociado con una reducción (multiplicativa) del ratio entre las probabilidades de  `\(j\)` vs `\(J\)`

--

- Si `\(\beta_{jk} = 0  \to  (e^{\beta_{jk}} =1)\)`. Es decir, un cambio en `\(x_{k}\)` está asociado a un cambio nulo en el ratio entre las probabilidades de  `\(j\)` vs `\(J\)`

--

- Si `\(\beta_{jk} &gt; 0  \to  (e^{\beta_{jk}} &gt; 1)\)`. Es decir, un aumento en `\(x_{k}\)` está asociado a aumento (multiplicativo) en el ratio entre las probabilidades de  `\(j\)` vs `\(J\)`


---
## Efectos multiplicativos sobre las odds 

En nuestro ejemplo: `\(\ln \frac{p_{ij}}{p_{iJ}} = \beta_{j0} + \beta_{j1}\text{statusquo}_{i} + \beta_{j2}\text{male}_{i}\)`, por tanto:
  
  
.pull-left[
  `\(\frac{p_{ij}}{p_{iJ}} = e^{\beta_{j0}} \cdot  e^{\beta_{j1}\text{statusquo}_{i}} \cdot e^{ \beta_{j2}\text{male}_{i} }\)`
      

```r
# coeffs
summary(mlogit_vote_sq_sex)$coefficients
```

```
##   (Intercept)  statusquo       sexM
## N   0.1099473 -1.7644993  0.6981650
## U   1.2905014  0.3357059 -0.2920198
## Y   0.7772821  1.8948940 -0.1141098
```

```r
# exp(coeffs)
exp(summary(mlogit_vote_sq_sex)$coefficients)
```

```
##   (Intercept) statusquo      sexM
## N    1.116219 0.1712725 2.0100610
## U    3.634609 1.3989276 0.7467538
## Y    2.175551 6.6518429 0.8921600
```
    
]

--
  
.pull-right[
  ![](class_13_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;
]

---
## Efectos multiplicativos sobre las odds

.pull-left[

```
##        beta1 exp.beta1
## N -1.7644993 0.1712725
## U  0.3357059 1.3989276
## Y  1.8948940 6.6518429
```
]

.pull-right[
Si `male=1` y `statusquo=0`, entonces las odds de N e Y son=

```r
c(N=exp(0.11 -1.76*0 + 0.7*1),
  Y=exp(0.78  + 1.9*0 + -0.11*1) )
```

```
##        N        Y 
## 2.247908 1.954237
```

Si `male=1` y `statusquo=1`,  entonces las odds de N e Y son=

```r
c(N=exp(0.11 -1.76*1 + 0.7*1),
  Y=exp(0.78  + 1.9*1 + -0.11*1))
```

```
##         N         Y 
##  0.386741 13.065824
```
]


---
## Efectos multiplicativos sobre las odds

.pull-left[

```
##        beta1 exp.beta1
## N -1.7644993 0.1712725
## U  0.3357059 1.3989276
## Y  1.8948940 6.6518429
```


&lt;br&gt;
Por tanto, `\(e^{\beta_{N1}}\)` y `\(e^{\beta_{Y1}}\)` son=



```r
c(
betaN1 = exp(0.11 -1.76*1 + 0.7*1)/exp(0.11 -1.76*0 + 0.7*1),
betaY1 = exp(0.78 + 1.9*1 -0.11*1)/exp(0.78 + 1.9*0 -0.11*1)
)
```

```
##    betaN1    betaY1 
## 0.1720449 6.6858944
```
]

.pull-right[
Si `male=1` y `statusquo=0`, entonces las odds de N e Y son=

```r
c(N=exp(0.11 -1.76*0 + 0.7*1),
  Y=exp(0.78  + 1.9*0 + -0.11*1) )
```

```
##        N        Y 
## 2.247908 1.954237
```

Si `male=1` y `statusquo=1`,  entonces las odds de N e Y son=

```r
c(N=exp(0.11 -1.76*1 + 0.7*1),
  Y=exp(0.78  + 1.9*1 + -0.11*1))
```

```
##         N         Y 
##  0.386741 13.065824
```
]


---
class:center, middle

## Efectos marginales sobre la probabilidad de la categoría `\(j\)`


---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`

--

Dado el siguiente modelo de regresión logística multinomial: 


`$$\text{logit}(p_{ij}) = \ln \frac{p_{ij}}{p_{iJ}} = \beta_{j0} + \beta_{j1} x_{i1} + \dots + \beta_{jk} x_{ik}$$`
&lt;br&gt;
--
Queremos saber el .bold[efecto marginal] de los predictores sobre la .bold[probabilidad] de observar cada categoría `\(j: \{1, \dots, J\}\)`. Formalmente

&lt;br&gt;
--

`$$\frac{\partial p_{ij}}{\partial x_{k}}$$`
--

`$$\vdots$$`

---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`

Después de varios pasos, obtenemos:

&lt;br&gt;
.content-box-yellow[
`$$\frac{\partial p_{ij}}{\partial x_{k}} = p_{ij} \cdot \bigg(\beta_{jk} - \sum^{J-1}_{j=1}p_{ij} \cdot \beta_{jk}\bigg)$$`
]

&lt;br&gt;
donde

`$$p_{ij} =\frac{e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}}{1 + \sum^{J-1}_{j=1}  e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}}$$`
---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`


.pull-left[
Analizando `$$\frac{\partial p_{ij}}{\partial x_{k}} = p_{ij} \cdot \bigg(\beta_{jk} - \sum^{J-1}_{j=1}p_{ij} \cdot \beta_{jk}\bigg)$$`
]

--

.pull-right[
podemos notar que  `\(\sum^{J-1}_{j=1}p_{ij} \cdot \beta_{jk} \equiv \overline{\beta_{jk}}, \quad\)` el "efecto promedio de" `\(x_k\)`. Se desprende que:
]

&lt;br&gt;
--

- El signo del efecto marginal de los predictores .bold[no necesariamente] corresponde al signo del parámetro estimado en la regresión. 
--

  - `\(\frac{\partial p_{ij}}{\partial x_{k}} &gt; 0 \quad\)`  si  `\(\quad \beta_{jk} &gt; \sum^{J-1}_{j=1}p_{j} \cdot \beta_{jk}\)`
  
  - `\(\frac{\partial p_{ij}}{\partial x_{k}} = 0 \quad\)`  si  `\(\quad \beta_{jk} = \sum^{J-1}_{j=1}p_{j} \cdot \beta_{jk}\)`

  - `\(\frac{\partial p_{ij}}{\partial x_{k}} &lt; 0 \quad\)`  si  `\(\quad \beta_{jk} &lt; \sum^{J-1}_{j=1}p_{j} \cdot \beta_{jk}\)`

&lt;br&gt;
--
.bold[Nota]: No tiene mucho sentido testear si efectos marginales son distintos de cero.


---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`

.pull-left[
si `$$\frac{\partial p_{ij}}{\partial x_{k}} = p_{j} \cdot \bigg(\beta_{jk} - \sum^{J-1}_{j=1}p_{j} \cdot \beta_{jk}\bigg)$$`
]

--

.pull-right[
y `$$p_{ij} =\frac{e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}}{1 + \sum^{J-1}_{j=1}  e^{\beta_{j0} + \beta_{j1}x_{1i} + \dots + \beta_{jk}x_{ki}}}$$` 
]


&lt;br&gt;
--

- Es claro que el efecto marginal de `\(x_{k}\)` varía dependiendo del valor de `\(x_{k}\)`, de su coeficiente `\(\beta_{jk}\)`, y de todas las otras covariables con sus respectivos coeficientes.

---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`

En nuestro ejemplo: `\(\ln \frac{p_{ij}}{p_{iJ}} = \beta_{j0} + \beta_{j1}\text{statusquo}_{i} + \beta_{j2}\text{male}_{i}\)`, por tanto:
  
  
.pull-left[
  `$$p_{ij} =\frac{e^{\beta_{j0} + \beta_{j1}\text{statusquo}_{i} + \beta_{j2}\text{male}_{i}}}{1 + \sum^{J-1}_{j=1} e^{\beta_{j0} + \beta_{j1}\text{statusquo}_{i} + \beta_{j2}\text{male}_{i}}}$$`
      
&lt;br&gt;      

```r
summary(mlogit_vote_sq_sex)$coefficients
```

```
##   (Intercept)  statusquo       sexM
## N   0.1099473 -1.7644993  0.6981650
## U   1.2905014  0.3357059 -0.2920198
## Y   0.7772821  1.8948940 -0.1141098
```
    
]


--
  
.pull-right[
![](class_13_files/figure-html/unnamed-chunk-27-1.png)&lt;!-- --&gt;
]

---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`


.pull-left[
`$$p_{ij} =\frac{e^{\beta_{j0} + \beta_{j1}\text{statusquo}_{i} + \beta_{j2}\text{male}_{i}}}{1 + \sum^{J-1}_{j=1} e^{\beta_{j0} + \beta_{j1}\text{statusquo}_{i} + \beta_{j2}\text{male}_{i}}}$$`

![](class_13_files/figure-html/unnamed-chunk-28-1.png)&lt;!-- --&gt;
]

.pull-right[
`$$\frac{\partial p_{ij}}{\partial x_{k}} = p_{j} \cdot \bigg(\beta_{jk} - \sum^{J-1}_{j=1}p_{j} \cdot \beta_{jk}\bigg)$$`

![](class_13_files/figure-html/unnamed-chunk-29-1.png)&lt;!-- --&gt;
]

---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`

- Efectos marginales son _esencialmente_ heterogéneos. No hay un efecto sino muchos. 

--

- Heterogeneidad crece con la complejidad del modelo: número de predictores, interacciones, etc. 

--

- Más aún, en el caso de modelos de regresión logística multinomial, los efectos marginales no son necesariamente monotónicos (pueden cambiar de signo).

--

- En la práctica, muchas veces queremos UN número que resuma el efecto marginal. 

&lt;br&gt;
--
.pull-left[
![For god sakes just give me the damn number](https://i.makeagif.com/media/8-29-2018/ior4IF.gif)
]

--

Cantidades de interes:
.pull-right[

* Average Marginal Effects (AME)

* Marginal Effects at the Mean (MEM)

* Marginal Effects at Representative Values (MER)

]


---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`: AME

--

`$$\text{Aproximación numérica:} \quad \frac{1}{n} \sum_{i} \frac{\partial p_{ij}}{\partial x_{k}} \approx  \frac{1}{n} \sum_{i}  \frac{p_{ij}(x_{1}, \dots ,x_{k} = c + \delta) - p_{ij}(x_{1}, \dots ,x_{k} = c )}{\delta}$$`
--

AME de apoyo al status-quo:

```r
delta = 0.1
p_hat &lt;- predict(mlogit_vote_sq_sex, type="probs") %&gt;% as_tibble()  %&gt;% mutate(id = row_number()) %&gt;% 
         pivot_longer(-id, names_to="vote", values_to="prob") 

plebs_1988_delta &lt;- plebs_1988 %&gt;% mutate(statusquo = statusquo + delta) 
p_hat_delta &lt;- predict(mlogit_vote_sq_sex, newdata=plebs_1988_delta ,type="probs")  %&gt;% as_tibble() %&gt;% mutate(id = row_number()) %&gt;% pivot_longer(-id, names_to="vote", values_to="prob_delta") 

p_hat_delta &lt;- p_hat_delta %&gt;% left_join(p_hat, by=c("id","vote")) %&gt;% mutate(me_sq = (prob_delta  - prob)/delta) %&gt;% dplyr::select(id,vote,me_sq) %&gt;% pivot_wider(names_from = "vote", values_from = "me_sq") %&gt;% drop_na()
```

--



```r
p_hat_delta %&gt;% dplyr::summarise(across(A:Y, ~ mean(.x)))
```

```
## # A tibble: 1 × 4
##         A      N      U     Y
##     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1 0.00663 -0.255 0.0273 0.221
```

---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`: AME

--

Usando el paquete `marginaleffects`:


```r
avg_slopes(mlogit_vote_sq_sex, variables="statusquo")
```

```
## 
##  Group      Term Estimate Std. Error      z Pr(&gt;|z|)    S     2.5 %   97.5 %
##      A statusquo  0.00448    0.00181   2.47   0.0135  6.2  0.000924  0.00803
##      N statusquo -0.26361    0.00372 -70.86   &lt;0.001  Inf -0.270898 -0.25632
##      U statusquo  0.02473    0.00348   7.11   &lt;0.001 39.7  0.017914  0.03154
##      Y statusquo  0.23440    0.00210 111.83   &lt;0.001  Inf  0.230293  0.23851
## 
## Columns: term, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high 
## Type:  probs
```

---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`: MEM

`$$\text{Aproximación numérica:} \quad \frac{\partial p_{ij}}{\partial x_{k}} \approx  \frac{p_{ij}(x_{1}=\bar{x_{1}}, \dots ,x_{k} = \bar{x_{k}} + \delta) - p_{ij}(x_{1}=\bar{x_{1}}, \dots ,x_{k} =\bar{x_{k}} )}{\delta}$$`
--
MEM de apoyo al status-quo:

```r
delta = 0.1; grid &lt;- plebs_1988 %&gt;% data_grid(sex, .model=mlogit_vote_sq_sex)
grid_delta &lt;- plebs_1988 %&gt;% data_grid(sex, .model=mlogit_vote_sq_sex) %&gt;% mutate(statusquo = statusquo + delta)

p_hat &lt;- predict(mlogit_vote_sq_sex, type="probs", newdata =grid) %&gt;% as_tibble() %&gt;% 
  mutate(id = c("F","M"))%&gt;% pivot_longer(-id, names_to="vote", values_to="prob") 

p_hat_delta &lt;- predict(mlogit_vote_sq_sex, type="probs", newdata =grid_delta) %&gt;% as_tibble() %&gt;% 
  mutate(id = c("F","M")) %&gt;% pivot_longer(-id, names_to="vote", values_to="prob_delta") 

p_hat_delta &lt;- p_hat_delta %&gt;% left_join(p_hat, by=c("id","vote")) %&gt;% mutate(me_sq = (prob_delta  - prob)/delta) %&gt;% dplyr::select(id,vote,me_sq) %&gt;% pivot_wider(names_from = "vote", values_from = "me_sq") %&gt;% drop_na(); p_hat_delta
```

```
## # A tibble: 2 × 5
##   id          A      N       U     Y
##   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1 F     -0.0542 -0.306 -0.0436 0.404
## 2 M     -0.0111 -0.521  0.0852 0.447
```

---
## Efectos marginales sobre la probabilidad de la categoría `\(j\)`: MEM

--

Usando el paquete `marginaleffects`:



```r
grid &lt;- plebs_1988 %&gt;% data_grid(sex, .model=mlogit_vote_sq_sex)
marginaleffects(mlogit_vote_sq_sex, variables="statusquo", newdata=grid)
```

```
## 
##  Group      Term  Estimate Std. Error        z Pr(&gt;|z|)     S   2.5 %  97.5 %
##      A statusquo -0.047033     0.0117  -4.0106   &lt;0.001  14.0 -0.0700 -0.0240
##      A statusquo  0.000272     0.0118   0.0229    0.982   0.0 -0.0229  0.0235
##      N statusquo -0.330959     0.0192 -17.2699   &lt;0.001 219.6 -0.3685 -0.2934
##      N statusquo -0.543301     0.0213 -25.5651   &lt;0.001 476.5 -0.5850 -0.5016
##      U statusquo -0.014003     0.0205  -0.6815    0.496   1.0 -0.0543  0.0263
##      U statusquo  0.114537     0.0207   5.5260   &lt;0.001  24.9  0.0739  0.1552
##      Y statusquo  0.391995     0.0165  23.7259   &lt;0.001 411.0  0.3596  0.4244
##      Y statusquo  0.428492     0.0217  19.7362   &lt;0.001 285.6  0.3859  0.4710
## 
## Columns: rowid, term, group, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted, sex, statusquo, vote 
## Type:  probs
```


---
class: inverse, center, middle

## Independence of Irrelevant Alternatives (IIA)


---
## Independence of Irrelevant Alternatives (IIA)

--

- Cuando regresión logística Multinomial es utilizada para modelar decisiones (choice), el modelo descansa en el supuesto implícito de IIA

--

- IIA: las odds (probabilidades relativas) de seleccionar cualquiera de las `\(J\)` alternativas no son afectadas por la existencia de alternativas irrelavantes.

&lt;br&gt;
--
.bold[Ejemplo] (McFadden’s 1974):

-  Una persona puede viajar al trabajo en: `\(\{\text{auto}, \text{ bus rojo}\}\)`
-  `\(\mathbb{P}(\text{auto}) =  \mathbb{P}(\text{ bus rojo}) = 1/2\)`. Odds=1.

--

- Supongamos se amplía el conjunto de alternativas: `\(\{\text{auto}, \text{ bus rojo},  \text{ bus azul}\}\)`

--

- Dado que los buses sólo difieren en color, esperaríamos que `\(\mathbb{P}(\text{ bus rojo}) = \mathbb{P}(\text{bus azul})\)`

- Único modo de retener Odds entre auto y bus rojo es si: `\(\mathbb{P}(\text{auto}) =  \mathbb{P}(\text{ bus rojo}) = \mathbb{P}(\text{bus azul}) = 1/3\)`

--

- Sería más realista esperar que `\(\mathbb{P}(\text{auto}) = 1/2)\)` y `\(\quad \mathbb{P}(\text{ bus rojo}) = \mathbb{P}(\text{bus azul}) = 1/4\)`

 - Sin embargo, violaría IIA porque las odds entre auto y bus rojo serían (1/2)/(1/4)=2.

---
## Independence of Irrelevante Alternatives (IIA)

Existe una variedad de tests para el supuesto de IIA, pero ninguno ha mostrado ser concluyente:

.center[
![iia](iia.png)
]


---
class: inverse, center, middle


##Hasta la próxima clase. Gracias!


&lt;br&gt;
Mauricio Bucca &lt;br&gt;
https://mebucca.github.io/ &lt;br&gt;
github.com/mebucca




    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
