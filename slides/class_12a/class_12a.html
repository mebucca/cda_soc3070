<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>An√°lisis de Datos Categ√≥ricos (SOC3070)</title>
    <meta charset="utf-8" />
    <meta name="author" content="  Mauricio Bucca  Profesor Asistente, Sociolog√≠a UC" />
    <script src="libs/header-attrs-2.29/header-attrs.js"></script>
    <link rel="stylesheet" href="gentle-r.css" type="text/css" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# An√°lisis de Datos Categ√≥ricos (SOC3070)
]
.subtitle[
## Regresi√≥n Log√≠stica para Predicci√≥n
]
.author[
### <br> Mauricio Bucca<br> Profesor Asistente, Sociolog√≠a UC
]

---

class: inverse, center, middle




# Evaluaci√≥n de Modelos Predictivos

---

## `\(\hat{\beta}\)`-problems vs. `\(\hat{y}\)`-problems

(Mullainathan &amp; Spiess, 2017) 


--

.pull-left[
### `\(\hat{\beta}\)`-problems

- Foco en **par√°metros** y su interpretaci√≥n.  

- Preguntas:  
  - ¬øCu√°l es el efecto de `\(X\)` sobre `\(Y\)`?  
  - ¬øEs significativo / causal?  
  
- Objetivo: **explicaci√≥n e inferencia**.  

- Modelos suelen ser **transparentes** (f√°cil interpretar).  
]

.pull-right[
### `\(\hat{y}\)`-problems  

- Foco en **predicciones** para nuevos casos.  

- Preguntas:  
  - ¬øQu√© tan bien predice el modelo en datos futuros?  
  - ¬øQu√© modelo predice mejor?  
  
- Objetivo: **desempe√±o y utilidad pr√°ctica**.  

- Modelos pueden ser tratados como **black-box** (no importa c√≥mo, mientras prediga bien).  
]

---
class: inverse, center, middle

## Regresi√≥n Log√≠stica como Machine Learning

---
## Regresi√≥n Log√≠stica como Machine Learning

&lt;br&gt;&lt;br&gt;
&lt;br&gt;

.middle[
.center[
![](https://www.researchgate.net/publication/376856079/figure/fig1/AS:11431281226110814@1709092685557/Famous-internet-meme-displaying-the-relation-between-statistics-Machine-Learning-and.png)
]
]
---
# Regresi√≥n Log√≠stica: el **‚Äúhello world‚Äù** de ML

&lt;br&gt;

- **Qu√© resuelve:**  

  - Estima la probabilidad de un evento binario (`\(Y=0/1\)`).  
  - Ejemplos: ¬øun mail es spam? ¬øalguien tendr√° una aventura?  

&lt;br&gt;

- **C√≥mo funciona:**  

  - Ajusta una combinaci√≥n lineal de predictores `\(X\beta\)`.  
  - Pasa ese valor por la **curva sigmoide** ‚Üí convierte log-odds en probabilidades (0‚Äì1).  
  - Aprende de los datos para **generalizar** a casos no observados (nuevos datos, futuro, etc.).  

&lt;br&gt;

- **Por qu√© es importante:**  

  - Interpretable: cada predictor tiene un rol claro en la probabilidad.  
  - Eficiente: funciona bien incluso con muestras peque√±as.  
  - Fundacional: es la base sobre la cual se construyen modelos m√°s complejos en ML.  


---

## Ejemplo emp√≠rico

`$$\newcommand{\vect}[1]{\boldsymbol{#1}}$$`



Continuando con el ejemplo de clases anteriores, ajustamos el siguiente modelo:

`$$\ln \frac{p_{i}}{1-p_{i}} = \beta_{0} + \beta_{1}\text{ym}_{i} + \beta_{2}\text{male}_{i} + \beta_{3}\text{rate}_{i} + \beta_{4}\text{rate}^{2}_{i}$$`

Llamemos a este modelo, modelo `\(M\)`:

&lt;br&gt;


```
##                     Estimate Std. Error    z value   Pr(&gt;|z|)
## (Intercept)      0.149861306 0.82300610  0.1820902 0.85551198
## ym               0.037699456 0.01813912  2.0783503 0.03767711
## factor(sex)male  0.249972343 0.19690565  1.2695032 0.20426166
## rate            -0.411820264 0.50252200 -0.8195069 0.41249725
## I(rate^2)       -0.008931688 0.07364745 -0.1212763 0.90347221
```

```
## [1] "log-likelihood: -316.105 Deviance: 632.21"
```

```
## [1] "AIC: 642.21 BIC: 664.202"
```

---
## Likelihood como funci√≥n de p√©rdida

- En ML, entrenar un modelo = encontrar par√°metros que **maximicen la verosimilitud**  
  (o equivalentemente **minimicen la p√©rdida**).  

--

- En regresi√≥n log√≠stica, cada `\(y_i\)` es Bernoulli con probabilidad `\(p_i\)`:  

$$
P(y_i \mid p_i) = p_i^{y_i}(1-p_i)^{1-y_i}
$$  

--

- La probabilidad conjunta de todos los datos:  

$$
\mathcal{L}(\beta) = \prod_{i=1}^{n} p_i^{y_i}(1-p_i)^{1-y_i}
$$  

--

- Tomando logaritmos:  

$$
\ell(\beta) = \sum_{i=1}^{n} \big[ y_i \ln p_i + (1-y_i) \ln(1-p_i) \big]
$$  

--

- En ML a esto le llamamos **log-loss** o **cross-entropy loss**:  

$$
\text{LogLoss} = -\ell(\beta)
$$  

---
## Likelihood como funci√≥n de p√©rdida

- Si las predicciones del modelo son correctas (`\(y=1\)` y `\(p\)` cercano a 1) ‚Üí log-loss bajo.
- Si se equivocan (`\(y=1\)` pero `\(p\)` cercano a 0) ‚Üí log-loss alto.
- Entrenar = **ajustar `\(\beta\)` para minimizar log-loss** (= maximizar likelihood).


Likelihood maximizada en nuestro ejemplo:


``` r
ll_m &lt;- logLik(logit_affairs); print(c(Likelihood = exp(ll_m[1]), log_likelihood = ll_m[1]))
```

```
##     Likelihood log_likelihood 
##  5.217357e-138  -3.161048e+02
```


--

.bold[Versi√≥n ML: Log-loss promedio ]

En machine learning se suele trabajar con la **log-loss promedio** para obtener una p√©rdida por observaci√≥n (comparable entre datasets de distinto tama√±o).


$$
\text{LogLoss} = -\frac{1}{n}\,\ell(\beta)
$$

``` r
n &lt;- length(affairsdata$everaffair_d); log_loss &lt;- -1/n * as.numeric(ll_m[1]); log_loss
```

```
## [1] 0.5259646
```


---

## Modelos de referencia (baselines)

En ML y estad√≠stica es com√∫n usar **modelos de referencia** para poner en contexto el desempe√±o de un modelo m√°s complejo.  Dos extremos:

--
&lt;br&gt;&lt;br&gt;

- **Modelo nulo (`\(M_N\)`)**  
  - El m√°s simple posible: siempre predice la probabilidad promedio global.  
  - Ventaja: parsimonioso y f√°cil de interpretar.  
  - Desventaja: genera las peores predicciones posibles√•, ignora covariables.  



``` r
# modelo nulo
logit_affairs_sex_null &lt;- glm(everaffair_d ~ 1,family=binomial(link="logit"), data=affairsdata)
```
--
&lt;br&gt;

- **Modelo saturado (`\(M_S\)`)**  
  - El m√°s complejo posible: ajusta un par√°metro distinto para cada observaci√≥n.  
  - Ventaja: fit perfecto (cero perdida).  
  - Desventaja: no generaliza ‚Üí memoriza los datos.  


``` r
# modelo saturado
logit_affairs_sex_sat &lt;- glm(everaffair_d ~ factor(1:nrow(affairsdata)) ,family=binomial(link="logit"), data=affairsdata)
```



---

## Baselines vs Modelo de Inter√©s

.center[
![dev](models.png)
]



---
## Residual Deviance y Null Deviance

En modelos log√≠sticos, el **log-likelihood ratio** puede re-expresarse como **Deviance**, que es esencialmente una medida de **p√©rdida (loss)**. Dos tipos de deviance:

&lt;br&gt;


- **Residual Deviance:**  `\(D = -2 \cdot (\log\mathcal{L}_{M} - \log \mathcal{L}_{S})\)`  
  - Eval√∫a el ajuste de `\(M\)` respecto al modelo saturado (fit perfecto).  

&lt;br&gt;

- **Null Deviance:** `\(D_N = -2 \cdot (\log\mathcal{L}_{0} - \log \mathcal{L}_{S})\)`  
  - Equivale al "total explicable", similar a la varianza total en OLS.  

&lt;br&gt;
--

- **Distribuci√≥n muestral:** `\(D \sim \chi^{2}(df = n-k), \quad  \text{donde k es el n√∫mero de par√°metros en M}\)`  


&lt;br&gt;

Interpretaci√≥n:

- `\(D\)` alto (p-value bajo) ‚Üí "mal ajuste" (alto error, modelo se queda corto).  
- `\(D\)` bajo (p-value alto) ‚Üí "buen ajuste" (m√°s par√°metros no agregan valor.  

---

## Residual Deviance y Null Deviance

.center[
![dev](deviances.png)
]

---
## Residual Deviance y Log-loss promedio

&lt;br&gt;


```
##                     Estimate Std. Error    z value   Pr(&gt;|z|)
## (Intercept)      0.149861306 0.82300610  0.1820902 0.85551198
## ym               0.037699456 0.01813912  2.0783503 0.03767711
## factor(sex)male  0.249972343 0.19690565  1.2695032 0.20426166
## rate            -0.411820264 0.50252200 -0.8195069 0.41249725
## I(rate^2)       -0.008931688 0.07364745 -0.1212763 0.90347221
```

```
## [1] "Null Deviance: 675.377 | Residual Deviance: 632.21"
```



``` r
# C√°lculo manual de la Residual Deviance
D &lt;- -2 * (logLik(logit_affairs)[1] - logLik(logit_affairs_sex_sat)[1])


# Relaci√≥n con log-loss promedio
log_likelihood &lt;- as.numeric(logLik(logit_affairs))
log_loss &lt;- -1/length(affairsdata$everaffair_d) * log_likelihood
print(paste0("Log-loss promedio: ", round(log_loss,4)))
```

```
## [1] "Log-loss promedio: 0.526"
```

---
## Pseudo - `\(R^2\)`

&lt;br&gt;
--

- En modelos OLS es com√∫n medir ajuste usando el coeficiente `\(R^2\)`, es decir, % de varianza explicada por el modelo.

--

- En GLM's la varianza no es separable de la media, por tanto no se puede descomponer.

--

- Existe una variedad de alternativas al `\(R^2\)`, llamadas gen√©ricamente pseudo - `\(R^2\)`. Uno de los m√°s comunes es:

&lt;br&gt;
--

`$$\text{McFadden‚Äôs } R^{2} = 1 - \frac{D}{D_{0}} = 1 - \frac{(\log\mathcal{L}_{S} - \log \mathcal{L}_{M})}{ (\log\mathcal{L}_{S} - \log \mathcal{L}_{N})}$$`
&lt;br&gt;
--

.bold[Intuici√≥n:]  fracci√≥n del total del "explicable" del likelihood que es explicado por el modelo `\(M\)`.

  - `\(R^{2} \in [0,1]\)`, donde 0 indica el peor fit posible y 1 indica el mejor fit posible. 

---
## Pseudo - `\(R^2\)`


```
##                     Estimate Std. Error    z value   Pr(&gt;|z|)
## (Intercept)      0.149861306 0.82300610  0.1820902 0.85551198
## ym               0.037699456 0.01813912  2.0783503 0.03767711
## factor(sex)male  0.249972343 0.19690565  1.2695032 0.20426166
## rate            -0.411820264 0.50252200 -0.8195069 0.41249725
## I(rate^2)       -0.008931688 0.07364745 -0.1212763 0.90347221
```

&lt;br&gt;
--

.bold[Residual deviance]:

``` r
R2 &lt;- 1 - logit_affairs$deviance/logit_affairs$null.deviance; R2
```

```
## [1] 0.06391612
```

``` r
# versi√≥n autom√°tica
PseudoR2(logit_affairs, which="McFadden")
```

```
##   McFadden 
## 0.06391612
```


---
class: inverse, center, middle

# Regresi√≥n Log√≠stica como clasificador
---

## De Probabilidades a clases


- La regresi√≥n log√≠stica entrega **scores probabil√≠sticos**:   `\(\hat{p}_i = \Pr(Y_i=1\mid X_i,\hat\beta)\)`

&lt;br&gt;
--

- Para convertir un score en decisi√≥n usamos un **umbral de corte** `\(\tau\)`:

$$
\hat{y}_i =
`\begin{cases}
1 &amp; \text{si } \hat{p}_i &gt; \tau \\
0 &amp; \text{si } \hat{p}_i \leq \tau
\end{cases}`
$$

&lt;br&gt;
--

- Por defecto: `\(\tau=0.5\)`  

- En ML, el umbral se ajusta al problema:  
  - Spam: es peor que se cuele spam ‚Üí corte bajo.  
  - Subsidio: es peor dejar fuera a quien lo necesita ‚Üí corte bajo.  
  - Examen de enfermedad peligrosa:
    - Detecci√≥n temprana: es peor no encontrar la enfermedad ‚Üí corte bajo.  
    - Confirmaci√≥n: es peor asustar a alguien sano ‚Üí corte alto.

.bold[üëâ Un clasificador es un modelo + una regla de decisi√≥n.]


---

## Matriz de Confusi√≥n

.center[
![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*mL-nYY6MFhiG0uoR5kJaCA.jpeg)
]
---

## Matriz de Confusi√≥n

.pull-left[
![](conf_mat.png)
]

.pull-right[
- **Accuracy**: `\((TP+TN)/N\)`  
  % de clasificaciones correctas  

- **Misclassification Rate**: `\((FP+FN)/N\)`  
  % de clasificaciones incorrectas  

- **True Positive Rate (Recall / Sensitivity)**:  
  `\(TP/(TP+FN)\)`  

- **True Negative Rate (Specificity)**:  
  `\(TN/(TN+FP)\)`  

- **Precision (PPV)**:  
  `\(TP/(TP+FP)\)`  

- **Prevalence**:  
  `\((TP+FN)/N\)`  
]

&lt;br&gt;
--

üìå Estas m√©tricas capturan distintos aspectos del desempe√±o de un clasificador.  
En ML es clave elegir m√©tricas alineadas con el problema (ej: medicina ‚â† marketing).  

---
## Ejemplo emp√≠rico: infidelidad

Clasificamos como ‚ÄúNunca infiel‚Äù a todas las personas cuya probabilidad predicha sea menor o igual a 0.5, y como ‚ÄúAl menos una vez‚Äù a aquellas cuya probabilidad predicha supere dicho umbral.

$$
\hat{y}_i =
`\begin{cases}
1 &amp; \text{si } \hat{p}_i &gt; 0.5 \quad (\text{Al menos una vez}) \\\\
0 &amp; \text{si } \hat{p}_i \leq 0.5 \quad (\text{Nunca infiel})
\end{cases}`
$$



``` r
p_hat &lt;- predict(logit_affairs, type = "response")
y_hat &lt;- if_else(p_hat&gt;0.5,1,0)

conf_mat &lt;- confusionMatrix(
  factor(y_hat), factor(logit_affairs$model$everaffair_d),
  positive = "1", dnn = c("Predicho","Real")
)


conf_mat$table
```

```
##         Real
## Predicho   0   1
##        0 438 137
##        1  13  13
```

---
## Ejemplo emp√≠rico: infidelidad

.pull-left[
![](class_12a_files/figure-html/unnamed-chunk-12-1.png)&lt;!-- --&gt;

]

.pull-right[

Table: M√©tricas principales del clasificador log√≠stico

|                  |     x|
|:-----------------|-----:|
|Sensitivity       | 0.087|
|Specificity       | 0.971|
|Precision         | 0.500|
|F1                | 0.148|
|Balanced Accuracy | 0.529|
]


---
## Umbral y predicci√≥n

- Cada umbral `\(\tau\)` genera un nivel de Especificidad y Sensibilidad: `\(:\{\text{Specificity}(\tau), \text{Sensitivity}(\tau)\}\)` para `\(\tau \in [0,1]\)`.



.pull-left[
![](class_12a_files/figure-html/plot_scores-1.png)&lt;!-- --&gt;
]

.pull-right[
- Umbrales bajos ‚Üí m√°s predicciones positivas
- Umbrales altos ‚Üí m√°s predicciones negativas
]

---
## Curva ROC

- La **curva ROC** conecta todos los puntos `\(:\{1 - \text{Specificity}(\tau), \quad \text{Sensitivity}(\tau)\}\)` para `\(\tau \in [0,1]\)`.

- La diagonal corresponde a un clasificador aleatorio.

- Mejor desempe√±o = curva m√°s arriba a la izquierda.

.pull-left[
![](class_12a_files/figure-html/plot_scores2-1.png)&lt;!-- --&gt;
]

.pull-right[
![](class_12a_files/figure-html/plot_roc-1.png)&lt;!-- --&gt;
]

---
## AUC: √Årea bajo la curva

- El **AUC** resume el desempe√±o en un solo n√∫mero: `\(AUC = \int_{0}^{1}\text{Sensibilidad}(\tau)\, d(1-\text{Especificidad}(\tau))\)`


- **Interpretaci√≥n**: probabilidad de que el modelo asigne mayor score a un positivo que a un negativo (elegidos al azar).


.pull-left[
![](class_12a_files/figure-html/plot_auc-1.png)&lt;!-- --&gt;
]

.pull-right[
**Interpretaci√≥n del AUC:**

- **AUC ‚âà 0.5**: Sin poder discriminatorio (como azar)

- **AUC ‚âà 0.7-0.8**: Discriminaci√≥n aceptable

- **AUC &gt; 0.9**: Discriminaci√≥n excelente

- **AUC = 1**: Clasificador perfecto

üëâ Nuestro modelo tiene AUC = 0.674, indicando poder discriminatorio moderado.
]

---
## Selecci√≥n del umbral √≥ptimo


- No existe un √∫nico "mejor" umbral: depende del contexto y los costos de errar.

- Criterios comunes: **Youden**, **punto m√°s cercano a (0,1)**, etc.

C√≥mo extraer umbrales en R:


``` r
# √çndice de Youden (maximiza TPR - FPR)
coords(roc_obj, x = "best", 
       best.method = "youden")
```

```
##   threshold specificity sensitivity
## 1  0.222457   0.5698448   0.6933333
```

``` r
# Punto m√°s cercano a (0,1)
coords(roc_obj, x = "best", 
       best.method = "closest.topleft")
```

```
##   threshold specificity sensitivity
## 1  0.222457   0.5698448   0.6933333
```

---
## Selecci√≥n del umbral √≥ptimo

- No existe un √∫nico "mejor" umbral: depende del contexto y los costos de errar.

- Criterios comunes: **Youden**, **punto m√°s cercano a (0,1)**, etc.

C√≥mo extraer umbrales en R:


``` r
# Ver todas las coordenadas
coords(roc_obj, x = "all") %&gt;% head(n=13)
```

```
##    threshold specificity sensitivity
## 1       -Inf  0.00000000   1.0000000
## 2  0.1069478  0.00886918   1.0000000
## 3  0.1080786  0.01773836   1.0000000
## 4  0.1100684  0.03991131   0.9866667
## 5  0.1162936  0.11308204   0.9733333
## 6  0.1268852  0.14412417   0.9400000
## 7  0.1331680  0.14855876   0.9333333
## 8  0.1345351  0.18181818   0.9200000
## 9  0.1370424  0.19068736   0.9200000
## 10 0.1430321  0.23059867   0.9133333
## 11 0.1488562  0.26164080   0.8933333
## 12 0.1574665  0.31707317   0.8666667
## 13 0.1649799  0.32150776   0.8666667
```

---
class: middle

## en el pr√≥ximo episodio ...


.center[
![cross](https://miro.medium.com/max/1224/1*hPDx1TYs9oMrbZRf-VYSUw.jpeg)
]



---
class: inverse, center, middle


##Hasta la pr√≥xima clase. Gracias!

&lt;br&gt;
Mauricio Bucca &lt;br&gt;
https://mebucca.github.io/ &lt;br&gt;
github.com/mebucca




    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
  "ratio": "16:9",
  "highlightStyle": "github",
  "highlightLines": true,
  "countIncrementalSlides": true,
  "slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
