---
title: "Análisis de Datos Categóricos (SOC3070)"
subtitle: "Regresión Logística para Predicción"
author: "<br> Mauricio Bucca<br> Profesor Asistente, Sociología UC"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["gentle-r.css","xaringan-themer.css"]
    df_print: default
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      slideNumberFormat: "%current%"
editor_options: 
  
  chunk_output_type: console
---  
class: inverse, center, middle

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(tidyverse)
library(xaringanthemer)
style_duo_accent(
  primary_color   = "#E4572E",   # naranja quemado (energía, foco)  
  secondary_color = "#29335C",   # azul marino profundo (contraste serio)  
  background_color = "#F4F1DE",  # beige claro, cálido y legible  
  header_font_google = google_font("Archivo"),  
  text_font_google   = google_font("Inconsolata"),  
  link_color = "#76B041"         # verde oliva brillante para resaltar  
)
```


# Evaluación de Modelos Predictivos

---

## $\hat{\beta}$-problems vs. $\hat{y}$-problems

(Mullainathan & Spiess, 2017) 


--

.pull-left[
### $\hat{\beta}$-problems

- Foco en **parámetros** y su interpretación.  

- Preguntas:  
  - ¿Cuál es el efecto de $X$ sobre $Y$?  
  - ¿Es significativo / causal?  
  
- Objetivo: **explicación e inferencia**.  

- Modelos suelen ser **transparentes** (fácil interpretar).  
]

.pull-right[
### $\hat{y}$-problems  

- Foco en **predicciones** para nuevos casos.  

- Preguntas:  
  - ¿Qué tan bien predice el modelo en datos futuros?  
  - ¿Qué modelo predice mejor?  
  
- Objetivo: **desempeño y utilidad práctica**.  

- Modelos pueden ser tratados como **black-box** (no importa cómo, mientras prediga bien).  
]

---
class: inverse, center, middle

## Regresión Logística como Machine Learning

---
## Regresión Logística como Machine Learning

<br><br>
<br>

.middle[
.center[
![](https://www.researchgate.net/publication/376856079/figure/fig1/AS:11431281226110814@1709092685557/Famous-internet-meme-displaying-the-relation-between-statistics-Machine-Learning-and.png)
]
]
---
# Regresión Logística: el **“hello world”** de ML

<br>

- **Qué resuelve:**  

  - Estima la probabilidad de un evento binario ($Y=0/1$).  
  - Ejemplos: ¿un mail es spam? ¿alguien tendrá una aventura?  

<br>

- **Cómo funciona:**  

  - Ajusta una combinación lineal de predictores $X\beta$.  
  - Pasa ese valor por la **curva sigmoide** → convierte log-odds en probabilidades (0–1).  
  - Aprende de los datos para **generalizar** a casos no observados (nuevos datos, futuro, etc.).  

<br>

- **Por qué es importante:**  

  - Interpretable: cada predictor tiene un rol claro en la probabilidad.  
  - Eficiente: funciona bien incluso con muestras pequeñas.  
  - Fundacional: es la base sobre la cual se construyen modelos más complejos en ML.  


---

## Ejemplo empírico

$$\newcommand{\vect}[1]{\boldsymbol{#1}}$$

```{r,  include=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# load data on extra-marital affairs from package "Ecdat"
library("Ecdat")
library("viridis")
library("tidyverse")
library("modelr")
library("cowplot")
library("margins")
library("rsample")
library("arm")
library("DescTools")
library("caret")

theme_set(theme_cowplot())

data(Fair)
affairsdata <- Fair %>% as_tibble()

# create a binary variable indicating wether persons has ever had an affair
affairsdata <- affairsdata %>% 
  mutate(everaffair = case_when(nbaffairs == 0 ~ "Never", nbaffairs > 0 ~ "At least once") ) %>%
  # map into 0/1 code
  mutate(everaffair_d = case_when(nbaffairs == 0 ~ 0, nbaffairs > 0 ~ 1))
```

Continuando con el ejemplo de clases anteriores, ajustamos el siguiente modelo:

$$\ln \frac{p_{i}}{1-p_{i}} = \beta_{0} + \beta_{1}\text{ym}_{i} + \beta_{2}\text{male}_{i} + \beta_{3}\text{rate}_{i} + \beta_{4}\text{rate}^{2}_{i}$$

Llamemos a este modelo, modelo $M$:

<br>

```{r,echo=FALSE}
logit_affairs <-  glm(everaffair_d ~ ym + factor(sex) + rate + I(rate^2) ,family=binomial(link="logit"), data=affairsdata)
summary(logit_affairs)$coefficients
print(paste0("log-likelihood: ",round(logLik(logit_affairs),3),
             " Deviance: ", round(summary(logit_affairs)$deviance,3) ))
print(paste0("AIC: ", round(summary(logit_affairs)$aic,3),
             " BIC: ", round(BIC(logit_affairs),3) ))
```

---
## Likelihood como función de pérdida

- En ML, entrenar un modelo = encontrar parámetros que **maximicen la verosimilitud**  
  (o equivalentemente **minimicen la pérdida**).  

--

- En regresión logística, cada $y_i$ es Bernoulli con probabilidad $p_i$:  

$$
P(y_i \mid p_i) = p_i^{y_i}(1-p_i)^{1-y_i}
$$  

--

- La probabilidad conjunta de todos los datos:  

$$
\mathcal{L}(\beta) = \prod_{i=1}^{n} p_i^{y_i}(1-p_i)^{1-y_i}
$$  

--

- Tomando logaritmos:  

$$
\ell(\beta) = \sum_{i=1}^{n} \big[ y_i \ln p_i + (1-y_i) \ln(1-p_i) \big]
$$  

--

- En ML a esto le llamamos **log-loss** o **cross-entropy loss**:  

$$
\text{LogLoss} = -\ell(\beta)
$$  

---
## Likelihood como función de pérdida

- Si las predicciones del modelo son correctas ($y=1$ y $p$ cercano a 1) → log-loss bajo.
- Si se equivocan ($y=1$ pero $p$ cercano a 0) → log-loss alto.
- Entrenar = **ajustar $\beta$ para minimizar log-loss** (= maximizar likelihood).


Likelihood maximizada en nuestro ejemplo:

```{r}
ll_m <- logLik(logit_affairs); print(c(Likelihood = exp(ll_m[1]), log_likelihood = ll_m[1]))
```


--

.bold[Versión ML: Log-loss promedio ]

En machine learning se suele trabajar con la **log-loss promedio** para obtener una pérdida por observación (comparable entre datasets de distinto tamaño).


$$
\text{LogLoss} = -\frac{1}{n}\,\ell(\beta)
$$
```{r}
n <- length(affairsdata$everaffair_d); log_loss <- -1/n * as.numeric(ll_m[1]); log_loss
```


---

## Modelos de referencia (baselines)

En ML y estadística es común usar **modelos de referencia** para poner en contexto el desempeño de un modelo más complejo.  Dos extremos:

--
<br><br>

- **Modelo nulo ($M_N$)**  
  - El más simple posible: siempre predice la probabilidad promedio global.  
  - Ventaja: parsimonioso y fácil de interpretar.  
  - Desventaja: genera las peores predicciones posibleså, ignora covariables.  


```{r,echo=TRUE, warning=FALSE,message=FALSE}
# modelo nulo
logit_affairs_sex_null <- glm(everaffair_d ~ 1,family=binomial(link="logit"), data=affairsdata)
```
--
<br>

- **Modelo saturado ($M_S$)**  
  - El más complejo posible: ajusta un parámetro distinto para cada observación.  
  - Ventaja: fit perfecto (cero perdida).  
  - Desventaja: no generaliza → memoriza los datos.  

```{r,echo=TRUE, warning=FALSE,message=FALSE}
# modelo saturado
logit_affairs_sex_sat <- glm(everaffair_d ~ factor(1:nrow(affairsdata)) ,family=binomial(link="logit"), data=affairsdata)
```



---

## Baselines vs Modelo de Interés

.center[
![dev](models.png)
]



---
## Residual Deviance y Null Deviance

En modelos logísticos, el **log-likelihood ratio** puede re-expresarse como **Deviance**, que es esencialmente una medida de **pérdida (loss)**. Dos tipos de deviance:

<br>


- **Residual Deviance:**  $D = -2 \cdot (\log\mathcal{L}_{M} - \log \mathcal{L}_{S})$  
  - Evalúa el ajuste de $M$ respecto al modelo saturado (fit perfecto).  

<br>

- **Null Deviance:** $D_N = -2 \cdot (\log\mathcal{L}_{0} - \log \mathcal{L}_{S})$  
  - Equivale al "total explicable", similar a la varianza total en OLS.  

<br>
--

- **Distribución muestral:** $D \sim \chi^{2}(df = n-k), \quad  \text{donde k es el número de parámetros en M}$  


<br>

Interpretación:

- $D$ alto (p-value bajo) → "mal ajuste" (alto error, modelo se queda corto).  
- $D$ bajo (p-value alto) → "buen ajuste" (más parámetros no agregan valor.  

---

## Residual Deviance y Null Deviance

.center[
![dev](deviances.png)
]

---
## Residual Deviance y Log-loss promedio

<br>

```{r,echo=FALSE}
# Coeficientes del modelo
summary(logit_affairs)$coefficients

# Null vs Residual Deviance reportados por R
print(paste0("Null Deviance: ", round(logit_affairs$null.deviance,3),
             " | Residual Deviance: ", round(summary(logit_affairs)$deviance,3) ))
```


```{r,echo=TRUE}
# Cálculo manual de la Residual Deviance
D <- -2 * (logLik(logit_affairs)[1] - logLik(logit_affairs_sex_sat)[1])


# Relación con log-loss promedio
log_likelihood <- as.numeric(logLik(logit_affairs))
log_loss <- -1/length(affairsdata$everaffair_d) * log_likelihood
print(paste0("Log-loss promedio: ", round(log_loss,4)))
```

---
## Pseudo - $R^2$

<br>
--

- En modelos OLS es común medir ajuste usando el coeficiente $R^2$, es decir, % de varianza explicada por el modelo.

--

- En GLM's la varianza no es separable de la media, por tanto no se puede descomponer.

--

- Existe una variedad de alternativas al $R^2$, llamadas genéricamente pseudo - $R^2$. Uno de los más comunes es:

<br>
--

$$\text{McFadden’s } R^{2} = 1 - \frac{D}{D_{0}} = 1 - \frac{(\log\mathcal{L}_{S} - \log \mathcal{L}_{M})}{ (\log\mathcal{L}_{S} - \log \mathcal{L}_{N})}$$
<br>
--

.bold[Intuición:]  fracción del total del "explicable" del likelihood que es explicado por el modelo $M$.

  - $R^{2} \in [0,1]$, donde 0 indica el peor fit posible y 1 indica el mejor fit posible. 

---
## Pseudo - $R^2$

```{r,echo=FALSE}
summary(logit_affairs)$coefficients
```

<br>
--

.bold[Residual deviance]:
```{r}
R2 <- 1 - logit_affairs$deviance/logit_affairs$null.deviance; R2

# versión automática
PseudoR2(logit_affairs, which="McFadden")
```


---
class: inverse, center, middle

# Regresión Logística como clasificador
---

## De Probabilidades a clases


- La regresión logística entrega **scores probabilísticos**:   $\hat{p}_i = \Pr(Y_i=1\mid X_i,\hat\beta)$

<br>
--

- Para convertir un score en decisión usamos un **umbral de corte** $\tau$:

$$
\hat{y}_i =
\begin{cases}
1 & \text{si } \hat{p}_i > \tau \\
0 & \text{si } \hat{p}_i \leq \tau
\end{cases}
$$

<br>
--

- Por defecto: $\tau=0.5$  

- En ML, el umbral se ajusta al problema:  
  - Spam: es peor que se cuele spam → corte bajo.  
  - Subsidio: es peor dejar fuera a quien lo necesita → corte bajo.  
  - Examen de enfermedad peligrosa:
    - Detección temprana: es peor no encontrar la enfermedad → corte bajo.  
    - Confirmación: es peor asustar a alguien sano → corte alto.

.bold[👉 Un clasificador es un modelo + una regla de decisión.]


---

## Matriz de Confusión

.center[
![](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*mL-nYY6MFhiG0uoR5kJaCA.jpeg)
]
---

## Matriz de Confusión

.pull-left[
![](conf_mat.png)
]

.pull-right[
- **Accuracy**: $(TP+TN)/N$  
  % de clasificaciones correctas  

- **Misclassification Rate**: $(FP+FN)/N$  
  % de clasificaciones incorrectas  

- **True Positive Rate (Recall / Sensitivity)**:  
  $TP/(TP+FN)$  

- **True Negative Rate (Specificity)**:  
  $TN/(TN+FP)$  

- **Precision (PPV)**:  
  $TP/(TP+FP)$  

- **Prevalence**:  
  $(TP+FN)/N$  
]

<br>
--

📌 Estas métricas capturan distintos aspectos del desempeño de un clasificador.  
En ML es clave elegir métricas alineadas con el problema (ej: medicina ≠ marketing).  

---
## Ejemplo empírico: infidelidad

Clasificamos como “Nunca infiel” a todas las personas cuya probabilidad predicha sea menor o igual a 0.5, y como “Al menos una vez” a aquellas cuya probabilidad predicha supere dicho umbral.

$$
\hat{y}_i =
\begin{cases}
1 & \text{si } \hat{p}_i > 0.5 \quad (\text{Al menos una vez}) \\\\
0 & \text{si } \hat{p}_i \leq 0.5 \quad (\text{Nunca infiel})
\end{cases}
$$


```{r}
p_hat <- predict(logit_affairs, type = "response")
y_hat <- if_else(p_hat>0.5,1,0)

conf_mat <- confusionMatrix(
  factor(y_hat), factor(logit_affairs$model$everaffair_d),
  positive = "1", dnn = c("Predicho","Real")
)


conf_mat$table
```

---
## Ejemplo empírico: infidelidad

.pull-left[
```{r, echo=FALSE}
df_pred <- tibble(
  p_hat = p_hat,
  y_true = logit_affairs$model$everaffair_d,
  y_hat = y_hat
)

ggplot(df_pred, aes(x=p_hat, fill=factor(y_true))) +
  geom_histogram(position="identity", alpha=0.6, bins=20) +
  geom_vline(xintercept=0.5, linetype="dashed", color="red") +
  scale_fill_manual(values=c("#00BFC4","#F8766D"),
                    name="Valor real", labels=c("0 = Nunca","1 = Al menos una vez")) +
  labs(title="Distribución de probabilidades predichas",
       x="Probabilidad estimada de infidelidad",
       y="Frecuencia") +
  theme_minimal()
```

]

.pull-right[
```{r, echo=FALSE}
# Seleccionar métricas clave
metrics <- conf_mat$byClass[c("Sensitivity","Specificity","Precision","F1","Balanced Accuracy")]

# Mostrar tabla ordenada
knitr::kable(round(metrics, 3), caption = "Métricas principales del clasificador logístico")
```
]


---
## Umbral y predicción

- Cada umbral $\tau$ genera un nivel de Especificidad y Sensibilidad: $:\{\text{Specificity}(\tau), \text{Sensitivity}(\tau)\}$ para $\tau \in [0,1]$.

```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
library(Ecdat)
library(tidyverse)
library(pROC)
library(ggrepel)

# Tema consistente
theme_set(theme_minimal(base_size = 14))
custom_theme <- theme(
  plot.title = element_text(face = "bold", size = 16),
  plot.subtitle = element_text(size = 12, color = "grey40"),
  legend.position = "top",
  panel.grid.minor = element_blank()
)

# Paleta de colores consistente
COLORS <- list(
  primary = "#FF4D6D",
  secondary = "#6C63FF",
  tertiary = "#00F5D4",
  positive = "#F8766D",
  negative = "#00BFC4",
  neutral = "grey60"
)

# Preparar datos
data(Fair)
df <- as_tibble(Fair) %>%
  mutate(y = if_else(nbaffairs > 0, 1L, 0L))

# Modelo logístico
m_logit <- glm(y ~ ym + factor(sex) + rate + I(rate^2),
               data = df, family = binomial)
p_hat <- predict(m_logit, type = "response")

# ROC
roc_obj <- roc(response = df$y, predictor = p_hat, quiet = TRUE)
roc_df <- coords(roc_obj, x = "all",
                 ret = c("specificity", "sensitivity", "threshold"),
                 transpose = FALSE) %>%
  as_tibble() %>%
  mutate(FPR = 1 - specificity, TPR = sensitivity) %>%
  arrange(FPR)

# Umbrales de ejemplo
calc_rates <- function(tau) {
  yhat <- as.integer(p_hat > tau)
  TP <- sum(yhat == 1 & df$y == 1)
  TN <- sum(yhat == 0 & df$y == 0)
  FP <- sum(yhat == 1 & df$y == 0)
  FN <- sum(yhat == 0 & df$y == 1)
  tibble(tau = tau, TPR = TP/(TP+FN), FPR = FP/(FP+TN))
}

taus <- c(0.2, 0.5, 0.8)
pts <- map_dfr(taus, calc_rates)
```

.pull-left[
```{r plot_scores, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6, fig.height=5}
# Panel A: Distribución de scores
ggplot(df, aes(x = p_hat, fill = factor(y))) +
  geom_histogram(aes(y = after_stat(count)), 
                 alpha = 0.7, bins = 30, position = "identity") +
  geom_vline(data = tibble(tau = taus, 
                          col = c(COLORS$tertiary, COLORS$primary, COLORS$secondary)),
             aes(xintercept = tau, color = col), 
             linetype = "dashed", linewidth = 1, show.legend = FALSE) +
  geom_label(data = tibble(x = taus, y = c(35, 30, 25),
                          txt = paste0("τ = ", taus)),
             aes(x = x, y = y, label = txt), 
             inherit.aes = FALSE, size = 4, fill = "white", 
             label.padding = unit(0.3, "lines")) +
  scale_fill_manual(values = c(COLORS$negative, COLORS$positive),
                    name = "Clase real:",
                    labels = c("Negativo (0)", "Positivo (1)")) +
  scale_color_identity() +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
  labs(title = "Distribución de scores por umbral",
       subtitle = "Cada τ define cómo clasificar las observaciones",
       x = "Score (probabilidad estimada)",
       y = "Frecuencia") +
  custom_theme +
  theme(legend.position = c(0.75, 0.88),
        legend.background = element_rect(fill = "white", color = NA))
```
]

.pull-right[
- Umbrales bajos → más predicciones positivas
- Umbrales altos → más predicciones negativas
]

---
## Curva ROC

- La **curva ROC** conecta todos los puntos $:\{1 - \text{Specificity}(\tau), \quad \text{Sensitivity}(\tau)\}$ para $\tau \in [0,1]$.

- La diagonal corresponde a un clasificador aleatorio.

- Mejor desempeño = curva más arriba a la izquierda.

.pull-left[
```{r plot_scores2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6, fig.height=5, ref.label='plot_scores'}
```
]

.pull-right[
```{r plot_roc, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6, fig.height=5}
# Panel B: Curva ROC
auc_val <- as.numeric(auc(roc_obj))

ggplot(roc_df, aes(x = FPR, y = TPR)) +
  geom_abline(slope = 1, intercept = 0, 
              linetype = "dashed", color = COLORS$neutral, linewidth = 0.8) +
  geom_path(linewidth = 1.5, color = COLORS$primary) +
  geom_point(data = pts, aes(x = FPR, y = TPR), 
             color = COLORS$secondary, size = 4, shape = 16) +
  geom_label_repel(data = pts,
                   aes(x = FPR, y = TPR, label = paste0("τ=", tau)),
                   size = 4, seed = 42, box.padding = 0.5,
                   min.segment.length = 0, segment.color = COLORS$secondary) +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1), expand = FALSE) +
  scale_x_continuous(breaks = seq(0, 1, 0.2)) +
  scale_y_continuous(breaks = seq(0, 1, 0.2)) +
  labs(subtitle = "Trade-off entre TPR y FPR según el umbral",
       x = "FPR (1 - Especificidad)",
       y = "TPR (Sensibilidad)") +
  custom_theme +
  theme(panel.grid.major = element_line(color = "grey90"))
```
]

---
## AUC: Área bajo la curva

- El **AUC** resume el desempeño en un solo número: $AUC = \int_{0}^{1}\text{Sensibilidad}(\tau)\, d(1-\text{Especificidad}(\tau))$


- **Interpretación**: probabilidad de que el modelo asigne mayor score a un positivo que a un negativo (elegidos al azar).


.pull-left[
```{r plot_auc, echo=FALSE, fig.width=6, fig.height=5}
# Modelo aleatorio para comparación
set.seed(123)
random_scores <- runif(nrow(df))
roc_random <- roc(df$y, random_scores, quiet = TRUE)

# Crear data frames para plotting
roc_model_df <- coords(roc_obj, x = "all", transpose = FALSE) %>%
  mutate(FPR = 1 - specificity, TPR = sensitivity, Model = "Logit")

roc_random_df <- coords(roc_random, x = "all", transpose = FALSE) %>%
  mutate(FPR = 1 - specificity, TPR = sensitivity, Model = "Aleatorio")

combined_df <- bind_rows(roc_model_df, roc_random_df)

ggplot(combined_df, aes(x = FPR, y = TPR, color = Model)) +
  geom_abline(slope = 1, intercept = 0, 
              linetype = "dashed", color = COLORS$neutral, linewidth = 0.8) +
  geom_path(linewidth = 1.5) +
  scale_color_manual(values = c("Logit" = COLORS$primary, 
                                "Aleatorio" = COLORS$neutral),
                    name = NULL) +
  coord_fixed(xlim = c(0, 1), ylim = c(0, 1), expand = FALSE) +
  scale_x_continuous(breaks = seq(0, 1, 0.2)) +
  scale_y_continuous(breaks = seq(0, 1, 0.2)) +
  labs(title = "Comparación de modelos",
       subtitle = paste0("AUC Logit = ", round(auc(roc_obj), 3), 
                        " | AUC Aleatorio ≈ 0.5"),
       x = "FPR (1 - Especificidad)",
       y = "TPR (Sensibilidad)") +
  custom_theme +
  theme(legend.position = c(0.8, 0.2),
        legend.background = element_rect(fill = "white", color = "grey80"),
        panel.grid.major = element_line(color = "grey90"))
```
]

.pull-right[
**Interpretación del AUC:**

- **AUC ≈ 0.5**: Sin poder discriminatorio (como azar)

- **AUC ≈ 0.7-0.8**: Discriminación aceptable

- **AUC > 0.9**: Discriminación excelente

- **AUC = 1**: Clasificador perfecto

👉 Nuestro modelo tiene AUC = `r round(auc(roc_obj), 3)`, indicando poder discriminatorio moderado.
]

---
## Selección del umbral óptimo


- No existe un único "mejor" umbral: depende del contexto y los costos de errar.

- Criterios comunes: **Youden**, **punto más cercano a (0,1)**, etc.

Cómo extraer umbrales en R:

```{r}
# Índice de Youden (maximiza TPR - FPR)
coords(roc_obj, x = "best", 
       best.method = "youden")

# Punto más cercano a (0,1)
coords(roc_obj, x = "best", 
       best.method = "closest.topleft")
```

---
## Selección del umbral óptimo

- No existe un único "mejor" umbral: depende del contexto y los costos de errar.

- Criterios comunes: **Youden**, **punto más cercano a (0,1)**, etc.

Cómo extraer umbrales en R:

```{r}
# Ver todas las coordenadas
coords(roc_obj, x = "all") %>% head(n=13)
```

---
class: middle

## en el próximo episodio ...


.center[
![cross](https://miro.medium.com/max/1224/1*hPDx1TYs9oMrbZRf-VYSUw.jpeg)
]



---
class: inverse, center, middle


##Hasta la próxima clase. Gracias!

<br>
Mauricio Bucca <br>
https://mebucca.github.io/ <br>
github.com/mebucca




