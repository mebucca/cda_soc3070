---
title: "SOC3070 Análisis de Datos Categóricos"
author: "Tarea corta 4"
format: html
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  comment = "#>",      # Python-style output prompt
  prompt = TRUE,       # Show > in front of code
  class.source = "python-code",
  class.output = "python-output"
)

# Packages
library(pacman)
p_load("tidyverse", "pROC","caret")

# Paleta julia definida como vector de colores
julia <- list(
  navy   = "#1f2041",
  teal   = "#4b8e8d",
  coral  = "#f87060",
  orange = "#f9a03f",
  sand   = "#ffd275"
)

# Paleta manual para usar en scales
julia_palette <- c(julia$coral, julia$teal, julia$orange, julia$navy, julia$sand)

# Theme con tipografía y estilo
theme_julia <- function() {
  theme_minimal(base_family = "Inconsolata") +
    theme(
      plot.background = element_rect(fill = "white", color = NA),
      panel.border = element_rect(fill=NA, color=julia$navy, size=0.6),
      axis.text = element_text(color=julia$navy, size=13),
      axis.title = element_text(color=julia$teal, size=15, face="bold"),
      plot.title = element_text(color=julia$coral, size=18, face="bold"),
      plot.subtitle = element_text(color=julia$orange, size=14),
      legend.position = "right"
    )
}

# Scales para color y fill
scale_color_julia <- function(...) {
  scale_color_manual(values = julia_palette, ...)
}

scale_fill_julia <- function(...) {
  scale_fill_manual(values = julia_palette, ...)
}
```

```{css, echo=FALSE}
pre.python-code, code.python-code {
  background-color: #f7f7f7;
  color: #222;
  font-family: "Inconsolata", monospace;
  font-size: 15px;
  border-left: 4px solid #ff6361;
  padding: 6px;
}
pre.python-output, code.python-output {
  background-color: #ffffff;
  color: #003f5c;
  font-family: "Inconsolata", monospace;
  font-size: 15px;
  padding: 6px;
}
```


Ponderación: 6% de la nota final del curso.

![Spam)](https://www.pandasecurity.com/en/mediacenter/src/uploads/2021/07/block-spam-yahoo-01-1.gif)

## Datos:

En esta tarea trabajaremos con el dataset **Spambase** disponible en el repositorio UCI: <https://archive.ics.uci.edu/dataset/94/spambase>

Este dataset contiene **4.601 correos electrónicos**, de los cuales aproximadamente el 40% son spam. Cada observación corresponde a un email y las variables predictoras son **57 características precomputadas** que incluyen:

-   Frecuencia relativa de palabras como "free", "money", etc.\
-   Frecuencia de caracteres como `;`, `(`, `[`.\
-   Longitud de secuencias de mayúsculas.

El objetivo es **clasificar correos como spam (1) o no-spam (0)**.

```{r, echo=F}
# ---- Cargar dataset ----
url <- "https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data"
colnames <- c(paste0("var", 1:57), "spam")
spam <- read.csv(url, header = FALSE, col.names = colnames)


# Asignar nombres a todas las variables del dataset Spambase
names(spam) <- c(
  # frecuencias de palabras
  "word_freq_make", "word_freq_address", "word_freq_all", "word_freq_3d",
  "word_freq_our", "word_freq_over", "word_freq_remove", "word_freq_internet",
  "word_freq_order", "word_freq_mail", "word_freq_receive", "word_freq_will",
  "word_freq_people", "word_freq_report", "word_freq_addresses", "word_freq_free",
  "word_freq_business", "word_freq_email", "word_freq_you", "word_freq_credit",
  "word_freq_your", "word_freq_font", "word_freq_000", "word_freq_money",
  "word_freq_hp", "word_freq_hpl", "word_freq_george", "word_freq_650",
  "word_freq_lab", "word_freq_labs", "word_freq_telnet", "word_freq_857",
  "word_freq_data", "word_freq_415", "word_freq_85", "word_freq_technology",
  "word_freq_1999", "word_freq_parts", "word_freq_pm", "word_freq_direct",
  "word_freq_cs", "word_freq_meeting", "word_freq_original", "word_freq_project",
  "word_freq_re", "word_freq_edu", "word_freq_table", "word_freq_conference",
  
  # frecuencias de caracteres
  "char_freq_semicolon",      # ;
  "char_freq_paren",          # (
  "char_freq_bracket",        # [
  "char_freq_exc",            # !
  "char_freq_dollar",         # $
  "char_freq_hash",           # #
  
  # atributos sobre mayúsculas
  "capital_run_length_average",
  "capital_run_length_longest",
  "capital_run_length_total",
  
  # variable dependiente
  "spam"
)

glimpse(spam)
```

## Tareas

1.  Ajusta dos modelos de regresión logística para predecir correos spam:

    -   Modelo 1 (parsimonioso / sustantivo): utiliza un pequeño conjunto de variables plausibles, por ejemplo `word_freq_free` (frecuencia de la palabra *free*), `char_freq_exc` (frecuencia del signo "!") y `capital_run_length_average` (longitud promedio de secuencias en mayúsculas).

    -   Modelo 2 (completo): incluye todas las variables disponibles en el dataset.

```{r, echo=T}
# Modelo 1: parsimonioso con variables sustantivas
m1 <- glm(spam ~ word_freq_free + word_freq_money + char_freq_exc +
            capital_run_length_average, data = spam, family = binomial)

# Modelo 2: completo con todas las variables
m2 <- glm(spam ~ ., data = spam, family = binomial)
```

2.  Para cada modelo, calcula las probabilidades predichas de ser spam para cada correo electrónico.

```{r, echo=T}
p1 <- predict(m1, type = "response")
p2 <- predict(m2, type = "response")
```

3.  Calcula manualmente el log-loss promedio de cada modelo.

```{r, echo=T}
logloss <- function(y, p) {
  -mean(y * log(p) + (1 - y) * log(1 - p))
}

ll1 <- logloss(spam$spam, p1); print(ll1)
ll2 <- logloss(spam$spam, p2); print(ll2)
```

4.  Grafica la curva ROC y calcula el AUC para ambos modelos.

```{r, echo=T}
roc1 <- roc(spam$spam, p1); plot(roc1)
roc2 <- roc(spam$spam, p2); plot(roc2)

auc1 <- auc(roc1); print(auc1)
auc2 <- auc(roc2); print(auc2)
```

5.  Con base en los resultados de (3) y (4), elige un modelo y define un umbral τ para clasificar correos como spam o no-spam.

El modelo mas complejo es más predictivo. Elegimos un umbral relativamente estricto: τ = 0.7

-   Con τ = 0.7 exigimos más "evidencia" antes de etiquetar un correo como spam.
-   Esto reduce falsos positivos (legítimos mal clasificados como spam), a costa de aumentar falsos negativos (spam que se cuelan).
-   Es razonable si nuestra prioridad es no perder correos legítimos.

```{r, echo=T}
tau <- 0.7
```

6.  Usando el modelo y umbral seleccionados en (5), construye una matriz de confusión. Elige una métrica relevante (accuracy, recall, precisión o F1), justifica tu elección e interpreta los resultados.

```{r, echo=T}
pred_class <- ifelse(p2 > tau, 1, 0)

cm <- confusionMatrix(factor(pred_class),
                      factor(spam$spam),
                      positive = "1")
print(cm)
```

El modelo clasifica correctamente el 91% de los correos (Accuracy). Del total de spam, el modelo detecta un 82% (Sensitivity/Recall). Del total de correos legítimos, el modelo reconoce correctamente un 97% (Specificity ≈ 97%).

Este modelo tiene buena performance pero prioriza minimizar falsos positivos (no molestar al usuario con mails legítimos marcados como spam), a costa de aceptar un cierto nivel de falsos negativos (spam que logra pasar).

7.  Repite la comparación entre ambos modelos utilizando validación cruzada k-fold. Evalúa si el modelo que considerabas mejor se mantiene como preferido o si cambia la conclusión. En caso de que cambie, explica por qué ocurrió este cambio. Finalmente, reporta los resultados de la matriz de confusión promediada a partir de la validación cruzada.


```{r}

library(tidyverse)
library(caret)
library(pROC)


set.seed(123)
ctrl <- trainControl(
  method = "cv",
  number = 10,
  summaryFunction = twoClassSummary,
  classProbs = TRUE,
  savePredictions = TRUE
)

spam$spam <- factor(ifelse(spam$spam == 1, "spam", "not_spam"))


m1_cv <- train(
  spam ~ word_freq_free + word_freq_money + char_freq_exc + capital_run_length_average,
  data = spam,
  method = "glm",
  family = "binomial",
  trControl = ctrl,
  metric = "ROC"
)

m2_cv <- train(
  spam ~ .,
  data = spam,
  method = "glm",
  family = "binomial",
  trControl = ctrl,
  metric = "ROC"
)

res <- resamples(list(M1 = m1_cv, M2 = m2_cv))
summary(res)

bwplot(res, main = "Comparación de desempeño por validación cruzada (10-fold)")
dotplot(res)
```

```{r}
# Obtener predicciones del modelo más predictivo
mean(m1_cv$results$ROC); mean(m2_cv$results$ROC)
```

Modelo con mejor AUC promedio es el más complejo.

```{r}
tau <- 0.7
preds <- m2_cv$pred

# Clasificación con τ = 0.7
preds$pred_tau <- ifelse(preds$spam > tau, "spam", "not_spam") |> factor(levels = c("not_spam", "spam"))

# Matriz de confusión promedio (promedio sobre folds)
cm <- confusionMatrix(preds$pred_tau, preds$obs, positive = "spam")
cm
```


El modelo completo mantiene un mejor desempeño promedio en validación cruzada,
con mayor AUC, confirmando que su complejidad se traduce en mejor capacidad
predictiva y generalización. La matriz de confusión promedio muestra alta sensibilidad y especificidad,
indicando que el modelo generaliza bien sin sobreajustar excesivamente.

