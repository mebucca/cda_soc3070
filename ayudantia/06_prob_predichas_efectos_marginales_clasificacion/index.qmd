---
title: "Probabilidades predichas, efectos marginales y clasificación"
subtitle: "Teoría y Aplicación"
author: "Cantillan, R. | Bucca, M."
institute: "ISUC"
page-layout: article
date: today
date-format: short
number-sections: true
format:
  html:
    theme:
      - cosmo
      - custom.scss
    css: custom.scss
    toc: true
    toc-depth: 3
    toc-title: "En este manual"
    toc-location: left
editor: visual
title-block-banner: true
title-block-style: default
title-block-categories: true
freeze: true
execute: 
  echo: fenced
  eval: true
  output: true
  warning: false
reference-location: margin
citation-location: margin
bibliography: catagorical_data.bib
---



## Librerías
```{r}
# librerías 
library(tidyverse)
library(marginaleffects)
library(kableExtra)
library(poLCA)
library(nnet)
library(httr)
library(utils)
library(margins)
#install.packages("pROC")
library(pROC)
#install.packages("ROSE")
library(ROSE)
library(reshape2)
```

## Cargamos datos 
```{r}
#ELSOC 2018
url <- "https://github.com/rcantillan/ricantillan.rbind.io/raw/main/dat/ELSOC/ELSOC_W03_v2.00_R.RData"
response <- GET(url)
local_path <- "ELSOC_W03_v2.00_R.RData"
writeBin(response$content, local_path)
load("ELSOC_W03_v2.00_R.RData") 
```

## Recodificación y selección de variables 
```{r}
# recod, and select 
a<-elsoc_2018%>%
  #mutate_at(vars(matches("c12")), ~ifelse(. > 1, 1, 2)) %>% 
  dplyr::mutate (conf_gral   = case_when(c02 == 1 ~ 1,  
                                         c02 == 2 ~ 0, 
                                         c02 == 3 ~ 0)) %>%
  #dplyr::mutate (extranjero  = case_when(m45 %in% 1 ~ 0,
  #                                       m45 %in% 2 :8 ~ 1)) %>% 
  dplyr::mutate (mujer       = case_when(m0_sexo == 1 ~ 0,
                                         m0_sexo == 2 ~ 1)) %>% 
  dplyr::mutate (edad        = case_when(m0_edad %in% 18:24 ~ "18_24",
                                         m0_edad %in% 25:34 ~ "25_34",
                                         m0_edad %in% 35:44 ~ "35_44",
                                         m0_edad %in% 45:54 ~ "45_54",
                                         m0_edad %in% 55:64 ~ "55_64", 
                                         m0_edad %in% 65:88 ~ "65")) %>%
  dplyr::mutate (nivel_educ  = case_when(m01 %in% 1 :3 ~ "básica",
                                         m01 %in% 4 :5 ~ "media",
                                         m01 %in% 6 :7 ~ "técnica",
                                         m01 %in% 8 :10 ~ "univers")) %>%
  mutate(across(matches("c12_"), 
                ~case_when(
                  . %in% c(-999, -888) ~ NA_real_,  # No Responde y No Sabe = NA
                  . == 3 ~ 2,  # Si es mayor que 1 (es decir, 2 o 3), asigna 1
                  TRUE ~ 1  # Para el resto (1), asigna 2
                ))) %>% 
  dplyr::select(idencuesta, mujer, edad, nivel_educ, c12_01:c12_09, conf_gral)

#elsoc_2018$c02

# set NA
a[a=="-999"] <- NA
a[a=="-888"] <- NA

# delete NA in covariable
a<-a %>% drop_na(mujer, edad, nivel_educ, c12_01:c12_09)
```

## Modelo de clases latentes 
```{r, message = FALSE}
set.seed(1234)
# usamos poLCA para realizar la clasificación 
f <- cbind(c12_01, c12_02, c12_03, c12_04, c12_05,
            c12_06, c12_07, c12_08, c12_09) ~ NULL

# generamos los modelos de clases latentes
lca1 <- poLCA(f,a,nclass=1,graphs=F)
lca2 <- poLCA(f,a,nclass=2,graphs=F)
lca3 <- poLCA(f,a,nclass=3,graphs=F)
lca4 <- poLCA(f,a,nclass=4,graphs=F)  
lca5 <- poLCA(f,a,nclass=5,graphs=F)  
lca6 <- poLCA(f,a,nclass=6,graphs=F)  

##  Estadísticos de ajuste (todos los modelos)
AIC.1 <-as.numeric(lca1$aic)
AIC.2 <-as.numeric(lca2$aic)
AIC.3 <-as.numeric(lca3$aic)
AIC.4 <-as.numeric(lca4$aic)
AIC.5 <-as.numeric(lca5$aic)
AIC.6 <-as.numeric(lca6$aic)

BIC.1 <-as.numeric(lca1$bic)
BIC.2 <-as.numeric(lca2$bic)
BIC.3 <-as.numeric(lca3$bic)
BIC.4 <-as.numeric(lca4$bic)
BIC.5 <-as.numeric(lca5$bic)
BIC.6 <-as.numeric(lca6$bic)

llik.1 <-as.numeric(lca1$llik)
llik.2 <-as.numeric(lca2$llik)
llik.3 <-as.numeric(lca3$llik)
llik.4 <-as.numeric(lca4$llik)
llik.5 <-as.numeric(lca5$llik)
llik.6 <-as.numeric(lca6$llik)

chisq.1 <- as.numeric(lca1$Chisq)
chisq.2 <- as.numeric(lca2$Chisq)
chisq.3 <- as.numeric(lca3$Chisq)
chisq.4 <- as.numeric(lca4$Chisq)
chisq.5 <- as.numeric(lca5$Chisq)
chisq.6 <- as.numeric(lca6$Chisq)

G.1 <- as.numeric(lca1$Gsq)
G.2 <- as.numeric(lca2$Gsq)
G.3 <- as.numeric(lca3$Gsq)
G.4 <- as.numeric(lca4$Gsq)
G.5 <- as.numeric(lca5$Gsq)
G.6 <- as.numeric(lca6$Gsq)

n.obs1 <- as.numeric(lca1$Nobs)
n.obs2 <- as.numeric(lca2$Nobs)
n.obs3 <- as.numeric(lca3$Nobs)
n.obs4 <- as.numeric(lca4$Nobs)
n.obs5 <- as.numeric(lca5$Nobs)
n.obs6 <- as.numeric(lca6$Nobs)

#Creación de Vectores para TABLA DE COMPARACIÓN
AIC <- c(AIC.1,AIC.2,AIC.3,AIC.4,AIC.5,AIC.6)
BIC <- c(BIC.1,BIC.2,BIC.3,BIC.4,BIC.5,BIC.6)
llik <- c(llik.1,llik.2,llik.3,llik.4,llik.5,llik.6)
chi.cuadrado <- c(chisq.1,chisq.2,chisq.3,chisq.4,chisq.5,chisq.6)
G2 <- c(G.1,G.2,G.3,G.4,G.5,G.6)
N <- c(n.obs1,n.obs2,n.obs3,n.obs4,n.obs5,n.obs6)
Modelos <- c("1 clase", "2 clases", "3 clases", "4 clases", "5 clases","6 clases")
```

```{r}
#CREACIÓN TABLA ESTADÍSTICOS DE AJUSTE MODELOS TODAS LAS VARIABLES
fit.indices <- data.frame(Modelos,AIC,BIC,llik,chi.cuadrado,G2,N)
knitr::kable(fit.indices, caption = "Indicadores de ajuste de los modelos")
fit.indices
```


### Mejor ajuste
```{r}
# best model. 
lca3 <- poLCA(f,a,nclass=3,graphs=T)
```


```{r}
#Extraer valores de inicio (modelo seleccionado)
probs.start<-lca3$probs.start
#lca3$probs.start

#Reordnar clases, si es necesario
new.probs.start<-poLCA.reorder(probs.start, c(3,2,1))

#Reanalizar con gráficos
lca3<-poLCA(f, a, nclass=3, probs.start=new.probs.start, graphs=T, na.rm=TRUE, maxiter=3000)


# Agregr columna de clasificación
a_lca <- cbind(a, "lclass" = lca3$predclass)
a_lca$lclass <- as.factor(a_lca$lclass) # definir factor


# Graficar patrones de membresías múltiples. 
lcmodel <- reshape2::melt(lca3$probs, level=2)
lcmodel <- lcmodel%>%
  dplyr::mutate(Var1=case_when(Var1=="class 1: "~"class 1\n(61%)",
                               Var1=="class 2: "~"class 2\n(26%)",
                               Var1=="class 3: "~"class 3\n(12%)")) %>% 
  mutate(class = factor(Var1, levels = c("class 1\n(61%)", "class 2\n(26%)", "class 3\n(12%)")))


lcmodel$L2 <- plyr::mapvalues(lcmodel$L2, 
                                  c('c12_01','c12_02','c12_03','c12_04','c12_05','c12_06','c12_07','c12_08', 'c12_09'),
                                  c("neighborhood","religious","political","union","professional","charity","sports","student", "other"))
level_order <- c("neighborhood","religious","charity","political","union","professional","sports","student", "other")
lcmodel$L2 <- factor(lcmodel$L2, levels = level_order)
lcmodel$Var2 <- ifelse(lcmodel$Var2 == "Pr(1)", "No", "Sí")


zp1 <- ggplot(lcmodel, aes(x = L2, y = value, fill = Var2)) +
  geom_bar(stat = "identity", position = "stack") +
  facet_wrap(~ class, ncol = 1, strip.position = "right") +
  theme(
    text = element_text(size=15),
    axis.ticks.y = element_blank(),
    legend.position = "top",
    panel.grid.major.y = element_blank(),
    plot.title = element_text(hjust = 0.5, size = 8),
    axis.title = element_text(size = 10),
    axis.text.x = element_text(size = 12, angle = 90, hjust = 1),
    axis.text.y = element_text(size = 10),
    strip.text.y = element_text(angle = 0),
    strip.background = element_blank()
  ) +
  labs(x = "", y = "", fill = "Es miembro?") +
  labs(x = "", y = "Pr (y)", title = "") +
  scale_fill_manual(values = c("Sí" = "#8e44ad", "No" = "#17202a")) +
  scale_y_continuous(labels = scales::percent_format(scale = 100))

print(zp1)
```


## Modelo de regresión lógistica

$$
\begin{align*}
\log\left(\frac{P(conf_gral = 1)}{1 - P(conf_gral = 1)}\right) = & \beta_0 \\
& + \beta_1 \cdot mujer \\
& + \beta_2 \cdot edad25_34 \\
& + \beta_3 \cdot edad35_44 \\
& + \beta_4 \cdot edad45_54 \\
& + \beta_5 \cdot edad55_64 \\
& + \beta_6 \cdot edad65 \\
& + \beta_7 \cdot nivel_educmedia \\
& + \beta_8 \cdot nivel_eductécnica \\
& + \beta_9 \cdot nivel_educunivers \\
& + \beta_{10} \cdot lclass2 \\
& + \beta_{11} \cdot lclass3
\end{align*}
$$
Donde:

- $\log\left(\frac{P(conf_gral = 1)}{1 - P(conf_gral = 1)}\right)$ es el logaritmo de las odds (logit) de $conf_gral = 1$

- $\beta_0$ es el intercepto

- $\beta_1, \beta_2, ..., \beta_{11}$ son los coeficientes de regresión para cada variable predictora

- $mujer$ es una variable binaria (0 = hombre, 1 = mujer)

- $edad25_34, edad35_44, ..., edad65$ son variables dummy para las categorías de edad (la categoría de referencia no aparece en la ecuación)

- $nivel_educmedia, nivel_eductécnica, nivel_educunivers$ son variables dummy para los niveles educativos (la categoría de referencia no aparece en la ecuación)

- $lclass2, lclass3$ son variables dummy para las clases latentes 2 y 3 (la clase latente 1 es la categoría de referencia)

## Modelo 1 
```{r}
# Regresión loística. 
m1 <- glm(conf_gral ~
            mujer + edad + nivel_educ + lclass,
          data = a_lca,
          family = "binomial")

summary(m1)
```


## Probabilidades Predichas

Las probabilidades predichas representan la probabilidad estimada de que ocurra el evento de interés (en este caso, $conf\_gral = 1$) para un conjunto específico de valores de las variables predictoras.

Notación:

- Sea $Y$ la variable dependiente binaria ($conf\_gral$)
- Sea $\mathbf{X}$ el vector de variables predictoras ($mujer$, $edad$, $nivel\_educ$, $lclass$)
- Sea $\boldsymbol{\beta}$ el vector de coeficientes estimados

La probabilidad predicha se denota como:

$$
P(Y = 1 | \mathbf{X} = \mathbf{x}) = \pi(\mathbf{x}) = \frac{1}{1 + e^{-\mathbf{x}\boldsymbol{\beta}}}
$$

Donde:

- $\pi(\mathbf{x})$ es la probabilidad predicha para un conjunto específico de valores $\mathbf{x}$
- $\mathbf{x}\boldsymbol{\beta}$ es el predictor lineal (la suma de los productos de cada variable predictora y su coeficiente correspondiente)

## Efectos Marginales

Los efectos marginales miden el cambio en la probabilidad predicha cuando una variable predictora cambia en una unidad, manteniendo todas las demás variables constantes.

Para una variable continua $X_j$, el efecto marginal se define como:

$$
\frac{\partial \pi(\mathbf{x})}{\partial X_j} = \pi(\mathbf{x})(1 - \pi(\mathbf{x}))\beta_j
$$

Para una variable categórica (como $lclass$), el efecto marginal al cambiar de la categoría de referencia a la categoría $k$ se calcula como:

$$
EM = P(Y = 1 | X_j = k) - P(Y = 1 | X_j = ref)
$$

Donde:

- $P(Y = 1 | X_j = k)$ es la probabilidad predicha cuando la variable $X_j$ está en la categoría $k$
- $P(Y = 1 | X_j = ref)$ es la probabilidad predicha cuando la variable $X_j$ está en la categoría de referencia

## Principales Diferencias

1. **Escala:**
   - Probabilidades Predichas: $\pi(\mathbf{x}) \in [0, 1]$
   - Efectos Marginales: $EM \in [-1, 1]$

2. **Interpretación:**
   - Probabilidades Predichas: Probabilidad absoluta de que $Y = 1$ para un conjunto específico de $\mathbf{X}$
   - Efectos Marginales: Cambio en la probabilidad de $Y = 1$ cuando $X_j$ cambia en una unidad o categoría

3. **Dependencia de otras variables:**
   - Probabilidades Predichas: Dependen de los valores específicos de todas las $\mathbf{X}$
   - Efectos Marginales: Se calculan manteniendo las demás variables constantes (usualmente en sus medias o en valores de referencia)

4. **Uso en el análisis:**
   - Probabilidades Predichas: Útiles para predecir el resultado para casos específicos
   - Efectos Marginales: Útiles para interpretar el impacto de cada variable en el modelo

## Ejemplo Numérico

Supongamos que para $lclass$ tenemos:

- $P(Y = 1 | lclass = 1) = 0.3$
- $P(Y = 1 | lclass = 2) = 0.4$
- $P(Y = 1 | lclass = 3) = 0.5$

Entonces:

- Las probabilidades predichas son 0.3, 0.4, y 0.5 para $lclass$ 1, 2, y 3 respectivamente.
- El efecto marginal de pasar de $lclass$ 1 a $lclass$ 2 es: $0.4 - 0.3 = 0.1$
- El efecto marginal de pasar de $lclass$ 1 a $lclass$ 3 es: $0.5 - 0.3 = 0.2$

Esto significa que, en promedio, pasar de la clase latente 1 a la 2 aumenta la probabilidad de $Y = 1$ en 0.1, mientras que pasar de la clase latente 1 a la 3 la aumenta en 0.2.

## Aplicación al Modelo de Clases Latentes

En el contexto de tu modelo de clases latentes:

1. Las probabilidades predichas te mostrarían la probabilidad estimada de $conf\_gral = 1$ para cada combinación de clase latente y otras características (como nivel educativo, edad, etc.).

2. Los efectos marginales te mostrarían cómo cambia esta probabilidad cuando pasas de una clase latente a otra, manteniendo las demás características constantes.

Esto te permite no solo predecir la probabilidad de $conf\_gral = 1$ para diferentes perfiles de individuos, sino también entender cómo la pertenencia a diferentes clases latentes influye en esta probabilidad, controlando por otros factores.


### Cálculo probabilidades predichas 
```{r}
# probabilidades predichas
# Crear un nuevo conjunto de datos
newdata <- expand.grid(
  mujer = 0,  # Hombre como referencia
  edad = "25_34",  # Edad de referencia
  nivel_educ = unique(a_lca$nivel_educ),  # Todos los niveles educativos
  lclass = factor(1:3)  # Las tres categorías de lclass como factor
)

# Asegurarse de que los niveles de lclass coincidan con los del modelo original
levels(newdata$lclass) <- levels(a_lca$lclass)

# Calcular probabilidades predichas
predicted_probs <- predict(m1, newdata = newdata, type = "response")

# Añadir las probabilidades predichas al conjunto de datos
newdata$prob = predicted_probs

# Crear el gráfico
ggplot(newdata, aes(x = lclass, y = prob, fill = nivel_educ)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9), width = 0.8) +
  geom_text(aes(label = sprintf("%.3f", prob)), 
            position = position_dodge(width = 0.9), 
            vjust = -0.5, size = 3) +
  labs(title = "Probabilidades predichas por clase latente y nivel educativo",
       x = "Clase latente",
       y = "Probabilidad predicha",
       fill = "Nivel educativo") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 0, hjust = 0.5),
        legend.position = "bottom") +
  ylim(0, max(newdata$prob) * 1.1) +  
  scale_fill_brewer(palette = "Set2") 

# Imprimir un resumen de las probabilidades predichas
print(newdata[order(newdata$lclass, newdata$nivel_educ), ])
```


### Cálculo efectos marginales
```{r}
# Efectos marginales. 
# Calcular los efectos marginales
marg_effects <- margins(m1, variables = c("lclass", ))

# Resumen de los efectos marginales
summary_marg <- summary(marg_effects)
print(summary_marg)

# Filtrar solo las filas relacionadas con lclass
lclass_effects <- summary_marg[grep("lclass", summary_marg$factor), ]

# Crear un dataframe para graficar
plot_data <- data.frame(
  lclass = factor(lclass_effects$factor),
  effect = lclass_effects$AME,
  lower = lclass_effects$lower,
  upper = lclass_effects$upper
)

# Crear el gráfico
ggplot(plot_data, aes(x = lclass, y = effect)) +
  geom_bar(stat = "identity", fill = "skyblue", width = 0.5) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2) +
  geom_text(aes(label = sprintf("%.3f", effect)), vjust = -0.5) +
  labs(title = "Efectos marginales promedio para lclass",
       x = "Clase latente",
       y = "Efecto marginal promedio") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(min(plot_data$lower) * 1.1, max(plot_data$upper) * 1.1)

# Imprimir los efectos marginales
print(plot_data)
```


## Clasificación 

En el contexto de la regresión logística, la clasificación se refiere al proceso de asignar cada observación a una de las dos categorías de la variable dependiente (en este caso, $conf_gral$) basándose en las probabilidades predichas por el modelo.

La idea básica es la siguiente:

El modelo de regresión logística produce una probabilidad predicha $\hat{p}$ para cada observación.
Se establece un umbral de decisión, comúnmente 0.5.
Si $\hat{p} \geq 0.5$, la observación se clasifica como 1 (tiene confianza general).
Si $\hat{p} < 0.5$, la observación se clasifica como 0 (no tiene confianza general).

Matemáticamente, podemos expresar esto como:
$$
\text{Clasificación} =
\begin{cases}
1 & \text{si } \hat{p} \geq 0.5 \
0 & \text{si } \hat{p} < 0.5
\end{cases}
$$
Donde $\hat{p} = P(conf_gral = 1 | X)$ es la probabilidad predicha por el modelo.
Evaluación de la Clasificación
Para evaluar la calidad de la clasificación, se utilizan varias métricas:

Exactitud (Accuracy): Proporción de predicciones correctas.
$$\text{Exactitud} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}$$
Sensibilidad (Sensitivity) o Tasa de Verdaderos Positivos: Proporción de positivos reales correctamente identificados.
$$\text{Sensibilidad} = \frac{\text{TP}}{\text{TP} + \text{FN}}$$
Especificidad (Specificity) o Tasa de Verdaderos Negativos: Proporción de negativos reales correctamente identificados.
$$\text{Especificidad} = \frac{\text{TN}}{\text{TN} + \text{FP}}$$

Donde TP = Verdaderos Positivos, TN = Verdaderos Negativos, FP = Falsos Positivos, FN = Falsos Negativos.



```{r, warning=FALSE, message=TRUE}

# 1. Preparar los datos
# Asumiendo que a_lca ya está cargado en el entorno
complete_cases <- complete.cases(a_lca[, c("conf_gral", "mujer", "edad", "nivel_educ", "lclass")])
a_lca_complete <- a_lca[complete_cases, ]

# Asegurar que las variables categóricas sean factores
a_lca_complete$edad <- as.factor(a_lca_complete$edad)
a_lca_complete$nivel_educ <- as.factor(a_lca_complete$nivel_educ)
a_lca_complete$lclass <- as.factor(a_lca_complete$lclass)

# 2. Calcular pesos para las clases
class_weights <- ifelse(a_lca_complete$conf_gral == 1, 
                        (1/table(a_lca_complete$conf_gral)[2]) * 0.5,
                        (1/table(a_lca_complete$conf_gral)[1]) * 0.5)

# 3. Entrenar el modelo con pesos
m1_weighted <- glm(conf_gral ~ mujer + edad + nivel_educ + lclass, 
                   data = a_lca_complete, 
                   family = "binomial",
                   weights = class_weights)

# 4. Evaluar el modelo con umbral 0.3
threshold <- 0.3
pred_probs <- predict(m1_weighted, newdata = a_lca_complete, type = "response")
pred_class <- ifelse(pred_probs > threshold, 1, 0)

conf_matrix <- table(Predicted = pred_class, Actual = a_lca_complete$conf_gral)

# 5. Calcular métricas
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
sensitivity <- conf_matrix[2,2] / sum(conf_matrix[,2])
specificity <- conf_matrix[1,1] / sum(conf_matrix[,1])
precision <- conf_matrix[2,2] / sum(conf_matrix[2,])
f1_score <- 2 * (precision * sensitivity) / (precision + sensitivity)
roc_obj <- roc(a_lca_complete$conf_gral, pred_probs)
auc_value <- auc(roc_obj)

# 6. Visualizar la matriz de confusión
ggplot(as.data.frame(conf_matrix), aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = sprintf("%d", Freq)), vjust = 1) +
  scale_fill_gradient(low = "white", high = "steelblue") +
  theme_minimal() +
  labs(title = "Matriz de Confusión (Umbral = 0.3)",
       subtitle = "Visualización de Verdaderos/Falsos Positivos/Negativos",
       x = "Valor Real",
       y = "Predicción") +
  scale_x_discrete(labels = c("No Confianza", "Confianza")) +
  scale_y_discrete(labels = c("No Confianza", "Confianza"))

# 7. Visualizar distribución de probabilidades predichas
ggplot(data.frame(prob = pred_probs, actual = factor(a_lca_complete$conf_gral)), aes(x = prob, fill = actual)) +
  geom_histogram(position = "identity", alpha = 0.5, bins = 50) +
  geom_vline(xintercept = threshold, linetype = "dashed", color = "red") +
  scale_fill_manual(values = c("blue", "green"), labels = c("No Confianza", "Confianza")) +
  labs(title = "Distribución de Probabilidades Predichas",
       subtitle = paste("Umbral de clasificación:", threshold),
       x = "Probabilidad Predicha",
       y = "Frecuencia",
       fill = "Valor Real") +
  theme_minimal()

# 8. Visualizar métricas de rendimiento
metrics <- data.frame(
  Metric = c("Exactitud", "Sensibilidad", "Especificidad", "Precisión", "F1-Score"),
  Value = c(accuracy, sensitivity, specificity, precision, f1_score)
)

ggplot(metrics, aes(x = Metric, y = Value)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  geom_text(aes(label = sprintf("%.3f", Value)), vjust = -0.5) +
  ylim(0, 1) +
  labs(title = "Métricas de Rendimiento del Modelo",
       subtitle = paste("Umbral de clasificación:", threshold),
       x = "",
       y = "Valor") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# 9. Visualizar curva ROC
ggplot(data.frame(FPR = 1 - roc_obj$specificities, TPR = roc_obj$sensitivities)) +
  geom_line(aes(x = FPR, y = TPR)) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "red") +
  annotate("text", x = 0.75, y = 0.25, 
           label = paste("AUC =", round(auc_value, 3))) +
  labs(title = "Curva ROC",
       x = "Tasa de Falsos Positivos (1 - Especificidad)",
       y = "Tasa de Verdaderos Positivos (Sensibilidad)") +
  theme_minimal()

# 10. Imprimir un resumen del modelo
summary(m1_weighted)
```

### Interpretación 

1. **Matriz de Confusión**:
   - La matriz de confusión nos muestra cómo se clasifican nuestras predicciones en comparación con los valores reales.
   - Los números en la diagonal (210 y 369) representan las predicciones correctas.
   - Los números fuera de la diagonal (6 y 3066) representan los errores de clasificación.
   - Observamos que hay un gran número de falsos positivos (3066), lo que indica que el modelo tiende a sobreestimar la confianza.

2. **Distribución de Probabilidades Predichas**:
   - Este gráfico nos muestra cómo el modelo asigna probabilidades a las observaciones.
   - La línea roja punteada representa nuestro umbral de clasificación (0.3).
   - Observamos que muchas observaciones de "No Confianza" (azul) están por encima del umbral, lo que explica los numerosos falsos positivos.

3. **Métricas de Rendimiento**:
   - Exactitud (0.159): Solo el 15.9% de todas las predicciones son correctas.
   - Sensibilidad (0.984): El modelo identifica correctamente el 98.4% de los casos reales de confianza.
   - Especificidad (0.064): Solo el 6.4% de los casos reales de no confianza son correctamente identificados.
   - Precisión (0.107): De todos los casos que el modelo predice como confianza, solo el 10.7% realmente lo son.
   - F1-Score (0.194): Este valor bajo refleja el desequilibrio entre la alta sensibilidad y la baja precisión.

4. **Curva ROC**:
   - La curva ROC nos muestra el rendimiento del clasificador a diferentes umbrales.
   - Un clasificador perfecto tendría un AUC de 1, mientras que uno aleatorio tendría 0.5.
   - Nuestro AUC de 0.675 indica que el modelo tiene cierta capacidad discriminativa, aunque no es excelente.

### Decisiones y Consideraciones

1. **Elección del Umbral**:
   - El umbral de 0.3 prioriza la sensibilidad sobre la especificidad.
   - Esto es útil si es crucial no perder casos reales de confianza, incluso a costa de muchos falsos positivos.

2. **Implicaciones Prácticas**:
   - Alta Sensibilidad: Casi todos los casos reales de confianza son identificados.
   - Baja Especificidad: Muchos casos de no confianza son clasificados erróneamente como confianza.
   - Considerar si el costo de los falsos positivos es aceptable en el contexto de tu investigación.

3. **Posibles Mejoras**:
   - Ajustar el umbral: Un umbral más alto podría mejorar la especificidad a costa de la sensibilidad.
   - Recolectar más datos o características: Esto podría mejorar la capacidad predictiva del modelo.
   - Explorar técnicas de balanceo de clases más avanzadas.

4. **Contexto de Uso**:
   - Este modelo podría ser útil como una herramienta de "screening" inicial, donde los casos identificados como positivos pasarían por una evaluación más detallada posteriormente.

En resumen, este modelo con un umbral de 0.3 es muy sensible pero poco específico. La decisión de usarlo dependerá de si es más importante capturar todos los casos positivos posibles o tener predicciones más precisas en general.









